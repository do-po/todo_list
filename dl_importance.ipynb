{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:13:53,193\tINFO worker.py:1604 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[디버깅] 작업 중요도 데이터 로드 중...\n",
      "[디버깅] 작업 중요도 데이터 로드 완료\n",
      "[디버깅] 작업 중요도 목표 변수 로드 중...\n",
      "[디버깅] 작업 중요도 목표 변수 로드 완료\n",
      "[디버깅] 범주형 데이터 원-핫 인코딩 중...\n",
      "[디버깅] 범주형 데이터 원-핫 인코딩 완료\n",
      "[디버깅] 데이터 정규화 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:13:53,479\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[디버깅] 데이터 정규화 완료\n",
      "[디버깅] 데이터 학습용 및 테스트용 분할 중...\n",
      "[디버깅] 데이터 학습용 및 테스트용 분할 완료\n",
      "93396\n",
      "23349\n",
      "93396\n",
      "23349\n",
      "[디버깅] 최적의 하이퍼파라미터 찾기 시작...\n",
      "[디버깅] Ray Tune 하이퍼파라미터 최적화 시작...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 174\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# 최적의 하이퍼파라미터 찾기\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     debug_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 하이퍼파라미터 찾기 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m     best_config, analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     debug_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 하이퍼파라미터 찾기 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m     debug_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 하이퍼파라미터로 모델 재학습 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[55], line 155\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Ray Tune을 사용하여 하이퍼파라미터 최적화 수행\u001b[39;00m\n\u001b[0;32m    154\u001b[0m debug_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRay Tune 하이퍼파라미터 최적화 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 155\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습 함수\u001b[39;49;00m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_cpus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_gpus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 각 시도에서 사용할 리소스 설정\u001b[39;49;00m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 하이퍼파라미터 설정\u001b[39;49;00m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 샘플링 횟수: 각 설정으로 몇 번의 실험을 실행할지\u001b[39;49;00m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 스케줄러 설정\u001b[39;49;00m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습 과정 출력 레벨: 0은 출력 없음, 1은 진행 상태 막대 표시, 2는 자세한 로그 출력\u001b[39;49;00m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 디렉토리 이름 생성 함수\u001b[39;49;00m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m debug_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRay Tune 하이퍼파라미터 최적화 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# 최적의 하이퍼파라미터 출력\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\tune.py:758\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, exp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(experiments):\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exp, Experiment):\n\u001b[1;32m--> 758\u001b[0m         experiments[i] \u001b[38;5;241m=\u001b[39m \u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_budget_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_budget_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources_per_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstorage_filesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_filesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[43msync_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrial_name_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_name_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_dirname_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlog_to_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_to_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexport_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_failures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fail_fast \u001b[38;5;129;01mand\u001b[39;00m max_failures \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_failures must be 0 if fail_fast=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\experiment\\experiment.py:149\u001b[0m, in \u001b[0;36mExperiment.__init__\u001b[1;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, sync_config, checkpoint_config, trial_name_creator, trial_dirname_creator, log_to_file, export_formats, max_failures, restore, local_dir)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_frequency\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot be set for a function trainable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to report a checkpoint every \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this behavior.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_identifier \u001b[38;5;241m=\u001b[39m \u001b[43mExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mrpc_code \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_raylet\u001b[38;5;241m.\u001b[39mGRPC_STATUS_CODE_RESOURCE_EXHAUSTED:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\experiment\\experiment.py:351\u001b[0m, in \u001b[0;36mExperiment.register_if_needed\u001b[1;34m(cls, run_object)\u001b[0m\n\u001b[0;32m    349\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_trainable_name(run_object)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 351\u001b[0m     \u001b[43mregister_trainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, PicklingError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    353\u001b[0m     extra_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther options: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-Try reproducing the issue by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe type annotations and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\registry.py:111\u001b[0m, in \u001b[0;36mregister_trainable\u001b[1;34m(name, trainable, warn)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(trainable, Trainable):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecond argument must be convertable to Trainable\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainable)\n\u001b[1;32m--> 111\u001b[0m \u001b[43m_global_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAINABLE_CLASS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\registry.py:238\u001b[0m, in \u001b[0;36m_Registry.register\u001b[1;34m(self, category, key, value)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_flush[(category, key)] \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps_debug(value)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _internal_kv_initialized():\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\registry.py:277\u001b[0m, in \u001b[0;36m_Registry.flush_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_atexit()\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (category, key), value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_flush\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    276\u001b[0m     _internal_kv_put(\n\u001b[1;32m--> 277\u001b[0m         \u001b[43m_make_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m, value, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     )\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered\u001b[38;5;241m.\u001b[39madd((category, key))\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_flush\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ray\\tune\\registry.py:194\u001b[0m, in \u001b[0;36m_make_key\u001b[1;34m(prefix, category, key)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_key\u001b[39m(prefix: \u001b[38;5;28mstr\u001b[39m, category: \u001b[38;5;28mstr\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a binary key for the given category and key.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m        The key to use for storing a the value.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuneRegistry:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;241m+\u001b[39m prefix\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;241m+\u001b[39m category\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 194\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "import os\n",
    "import multiprocessing\n",
    "from refer.module.func import debug_message, save_model_with_versioning\n",
    "import random\n",
    "\n",
    "# 시스템 정보 가져오기\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Ray 초기화\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# 데이터 로드 및 전처리 (DB에서 데이터 가져오기로 수정필요)\n",
    "file_path = './refer/output/'\n",
    "debug_message(\"작업 중요도 데이터 로드 중...\")\n",
    "data = pd.read_csv(f'{file_path}user_info.csv')\n",
    "debug_message(\"작업 중요도 데이터 로드 완료\")\n",
    "\n",
    "# 목표 변수 (중요도) 데이터 로드\n",
    "debug_message(\"작업 중요도 목표 변수 로드 중...\")\n",
    "target_data = pd.read_csv(f'{file_path}user_weight.csv')\n",
    "debug_message(\"작업 중요도 목표 변수 로드 완료\")\n",
    "\n",
    "# 범주형 데이터에 대한 원-핫 인코딩\n",
    "debug_message(\"범주형 데이터 원-핫 인코딩 중...\")\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(data[['gender', 'job', 'mbti']]).toarray()\n",
    "debug_message(\"범주형 데이터 원-핫 인코딩 완료\")\n",
    "\n",
    "# 인코딩된 데이터와 수치형 데이터를 결합\n",
    "numeric_data = data[['age']].values  # 나이 데이터는 별도로 결합\n",
    "X = np.hstack((encoded_data, numeric_data))\n",
    "\n",
    "# 데이터 정규화\n",
    "debug_message(\"데이터 정규화 중...\")\n",
    "scaler = StandardScaler()  # RobustScaler를 사용할 수도 있음\n",
    "X = scaler.fit_transform(X)\n",
    "debug_message(\"데이터 정규화 완료\")\n",
    "\n",
    "# 목표 변수 정의 (중요도)\n",
    "y = target_data[['work', 'edu', 'free_time', 'health', 'chores', 'category_else']].values\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "debug_message(\"데이터 학습용 및 테스트용 분할 중...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "debug_message(\"데이터 학습용 및 테스트용 분할 완료\")\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "# 모델 생성 함수\n",
    "def create_model(config):\n",
    "    debug_message(\"모델 생성 중...\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(config[\"hidden_layer1_size\"], input_dim=X_train.shape[1], activation='relu', \n",
    "                    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=config[\"l1_lambda\"], l2=config[\"l2_lambda\"])))\n",
    "    if config[\"batch_norm\"]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(config[\"dropout_rate\"]))\n",
    "    model.add(Dense(config[\"hidden_layer2_size\"], activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=config[\"l1_lambda\"], l2=config[\"l2_lambda\"])))\n",
    "    if config[\"batch_norm\"]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(config[\"dropout_rate\"]))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    model.compile(optimizer=tf.keras.optimizers.get(config[\"optimizer\"])(learning_rate=config[\"lr\"]),\n",
    "                  loss='mse',\n",
    "                  metrics=['mse'])  # MSE를 메트릭으로 추가\n",
    "    debug_message(\"모델 생성 완료\")\n",
    "    return model\n",
    "\n",
    "# 학습 함수\n",
    "@ray.remote\n",
    "def train_model(config, X_train, y_train, X_test, y_test):\n",
    "    print(\"train_model 함수에서 config는 \", config)\n",
    "    try:\n",
    "        debug_message(\"모델 학습 시작...\")\n",
    "        model = create_model(config)\n",
    "        log_dir = os.path.join(\"logs\", f\"trial_{tune.get_trial_id()[:8]}\")\n",
    "        os.makedirs(log_dir, exist_ok=True)  # 로그 디렉토리가 없으면 생성\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        tune_report_callback = TuneReportCallback({\"mean_squared_error\": \"val_mse\"})\n",
    "        history = model.fit(X_train, y_train, \n",
    "                            epochs=config[\"epochs\"], \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            validation_split=0.2, \n",
    "                            verbose=1,\n",
    "                            callbacks=[tensorboard_callback, tune_report_callback])\n",
    "        debug_message(\"모델 학습 완료\")\n",
    "        \n",
    "        # 모델 평가\n",
    "        debug_message(\"모델 평가 중...\")\n",
    "        train_loss = model.evaluate(X_train, y_train, verbose=1)\n",
    "        val_loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "        val_mse = mean_squared_error(y_test, y_pred_test)\n",
    "        debug_message(\"모델 평가 완료\")\n",
    "        \n",
    "        # 평가 결과 보고\n",
    "        tune.report(mean_squared_error=val_mse, train_loss=train_loss, val_loss=val_loss, train_mse=train_mse, val_mse=val_mse)\n",
    "    except Exception as e:\n",
    "        debug_message(f\"학습 중 오류 발생: {str(e)}\")\n",
    "        tune.report(mean_squared_error=float(\"inf\"), train_loss=float(\"inf\"), val_loss=float(\"inf\"), train_mse=float(\"inf\"), val_mse=float(\"inf\"))\n",
    "\n",
    "# 디렉토리 이름 생성 함수\n",
    "def trial_dirname_creator(trial):\n",
    "    trial_id = trial.trial_id if trial.trial_id else \"default_trial\"\n",
    "    return f\"trial_{trial_id}\"\n",
    "\n",
    "# Ray Tune을 사용한 하이퍼파라미터 최적화\n",
    "def tune_model():\n",
    "    config = {\n",
    "        'lr': tune.choice([0.0001, 0.01]),  # 학습률 결정: 학습 과정에서 가중치가 조정되는 속도\n",
    "        'batch_size': tune.choice([16, 64]),  # 배치 크기: 한 번의 훈련 반복에서 사용되는 샘플의 수\n",
    "        'epochs': tune.choice([50, 200]),  # 에포크 수: 전체 데이터셋을 훈련하는 반복 횟수\n",
    "        'hidden_layer1_size': tune.choice([64, 256]),  # 첫 번째 은닉층의 노드 수 결정: 모델의 복잡성 조절\n",
    "        'hidden_layer2_size': tune.choice([32, 128]),  # 두 번째 은닉층의 노드 수 결정: 모델의 복잡성 조절\n",
    "        'dropout_rate': tune.choice([0.1, 0.3]),  # 드롭아웃 비율: 과적합을 방지하기 위해 일부 뉴런을 무작위로 제외\n",
    "        'batch_norm': tune.choice([True, False]),  # 배치 정규화 사용 여부: 학습을 안정화하고 가속화\n",
    "        'optimizer': tune.choice(['adam']),  # 옵티마이저: 학습 과정에서 가중치를 업데이트하는 방법 결정\n",
    "        'l2_lambda': tune.choice([0.0001, 0.01]),  # L2 정규화: 가중치의 크기를 제한하여 과적합 방지\n",
    "        'l1_lambda': tune.choice([0.0001, 0.01]),  # L1 정규화: 가중치의 크기를 제한하여 과적합 방지\n",
    "        'num_cpus': num_cpus,  # CPU 수 설정\n",
    "        'num_gpus': num_gpus   # GPU 수 설정\n",
    "    }\n",
    "    # config에서 최대 에포크 값 추출\n",
    "    max_epochs = max(config['epochs'].categories)\n",
    "\n",
    "    # ASHA 스케줄러 설정: Asynchronous Successive Halving Algorithm\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"mean_squared_error\",  # 최적화할 메트릭\n",
    "        mode=\"min\",  # 최소화할 것인지, 최대화할 것인지 설정\n",
    "        max_t=max_epochs,  # 각 실험에서 실행할 최대 시간 또는 최대 스텝 (여기서는 에포크 수)\n",
    "        grace_period=1,  # 각 실험을 종료하기 전에 최소한으로 실행할 시간 또는 스텝\n",
    "        reduction_factor=2  # 리소스를 절감하기 위해 각 실험을 종료할 때마다 감소시킬 비율\n",
    "    )\n",
    "    \n",
    "    # Ray Tune을 사용하여 하이퍼파라미터 최적화 수행\n",
    "    debug_message(\"Ray Tune 하이퍼파라미터 최적화 시작...\")\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(train_model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test),  # 학습 함수\n",
    "        resources_per_trial={\"cpu\": config['num_cpus'], \"gpu\": config['num_gpus']},  # 각 시도에서 사용할 리소스 설정\n",
    "        config=config,  # 하이퍼파라미터 설정\n",
    "        num_samples=1,  # 샘플링 횟수: 각 설정으로 몇 번의 실험을 실행할지\n",
    "        scheduler=scheduler,  # 스케줄러 설정\n",
    "        verbose=1,  # 학습 과정 출력 레벨: 0은 출력 없음, 1은 진행 상태 막대 표시, 2는 자세한 로그 출력\n",
    "        trial_dirname_creator=trial_dirname_creator  # 디렉토리 이름 생성 함수\n",
    "        \n",
    "    )\n",
    "    debug_message(\"Ray Tune 하이퍼파라미터 최적화 완료\")\n",
    "    \n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best config: \", analysis.best_config)\n",
    "    return analysis.best_config, analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 최적의 하이퍼파라미터 찾기\n",
    "    debug_message(\"최적의 하이퍼파라미터 찾기 시작...\")\n",
    "    best_config, analysis = tune_model()\n",
    "    debug_message(\"최적의 하이퍼파라미터 찾기 완료\")\n",
    "    \n",
    "    debug_message(\"최적의 하이퍼파라미터로 모델 재학습 중...\")\n",
    "    best_model = create_model(best_config)\n",
    "    best_model.fit(X_train, y_train, epochs=best_config['epochs'], batch_size=best_config['batch_size'], validation_split=0.2, verbose=1)\n",
    "    debug_message(\"모델 재학습 완료\")\n",
    "    \n",
    "    # 최종 평가 결과\n",
    "    debug_message(\"최종 평가 결과 분석 중...\")\n",
    "    best_trial = analysis.get_best_trial(\"mean_squared_error\", mode=\"min\", scope=\"all\")\n",
    "    best_trained_model = create_model(best_trial.config)\n",
    "    best_checkpoint_dir = analysis.get_best_checkpoint(best_trial)\n",
    "\n",
    "    if best_checkpoint_dir:\n",
    "        model_path = os.path.join(best_checkpoint_dir, \"checkpoint\")\n",
    "        best_trained_model.load_weights(model_path)\n",
    "\n",
    "    debug_message(\"최종 모델 평가 중...\")\n",
    "    train_loss = best_trained_model.evaluate(X_train, y_train, verbose=1)\n",
    "    test_loss = best_trained_model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f'훈련 손실: {train_loss:.4f}')\n",
    "    print(f'테스트 손실: {test_loss:.4f}')\n",
    "    \n",
    "    y_pred_train = best_trained_model.predict(X_train)\n",
    "    y_pred_test = best_trained_model.predict(X_test)\n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f'훈련 MSE: {train_mse:.4f}')\n",
    "    print(f'테스트 MSE: {test_mse:.4f}')\n",
    "    debug_message(\"최종 모델 평가 완료\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    debug_message(\"모델 저장 중...\")\n",
    "    saved_filename = save_model_with_versioning(best_trained_model, file_path, \"importance_model\")\n",
    "    debug_message(f\"모델 저장 완료: {saved_filename}\")\n",
    "    \n",
    "    print(f\"Initial importance model created and saved as {saved_filename}.\")\n",
    "\n",
    "    # Ray 종료\n",
    "    ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
