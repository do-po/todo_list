{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설문 조사 데이터를 오버샘플링 하기 위한 코드\n",
    "- 샘플링 수를 늘려보자 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 랜덤 오버 샘플링을 위한 라이브러리\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파일 위치 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './refer/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설문 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survey_processing(file_path = f'{file_path}survey.csv', output_path = f'{file_path}survey_preprocessed.csv'):\n",
    "    # CSV 파일을 불러옵니다.\n",
    "    survey_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 우선순위에 대한 가중치 매핑을 정의합니다.\n",
    "    priority_weights = {\n",
    "        \"건강\": \"health\",\n",
    "        \"여가시간\": \"free_time\",\n",
    "        \"학업 및 자기계발\": \"edu\",\n",
    "        \"업무\": \"work\",\n",
    "        \"집안일\": \"chores\",\n",
    "        None: \"category_else\"\n",
    "    }\n",
    "    \n",
    "    # 각 우선순위 컬럼에 대해 가중치를 적용합니다.\n",
    "    for i in range(1, 6):\n",
    "        column_name = f\"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [{i} 순위]\"\n",
    "        survey_df[column_name] = survey_df[column_name].map(priority_weights)\n",
    "    \n",
    "    # 필요한 컬럼들만 선택하고 리네임합니다.\n",
    "    columns_to_keep = [\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\"\n",
    "    ]\n",
    "    \n",
    "    survey_df = survey_df[columns_to_keep]\n",
    "    \n",
    "    # 컬럼명을 변환합니다.\n",
    "    column_mapping = {\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\": \"age\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\": \"job\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\": \"mbti\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\": \"gender\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\": \"priority_1\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\": \"priority_2\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\": \"priority_3\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\": \"priority_4\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\": \"priority_5\"\n",
    "    }\n",
    "    \n",
    "    survey_df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    # 새로운 컬럼 'category_else'를 추가하고 모든 값을 0으로 설정합니다.\n",
    "    survey_df[\"category_else\"] = 0\n",
    "    \n",
    "    # 나이, 직업, MBTI 컬럼을 숫자 코드로 변환합니다.\n",
    "    age_mapping = {\n",
    "        \"0~14세\": (0, 14),\n",
    "        \"15~19세\": (15, 19),\n",
    "        \"20~24세\": (20, 24),\n",
    "        \"25~30세\": (25, 30),\n",
    "        \"31세 이상\": (31, 45)\n",
    "    }\n",
    "    job_mapping = {\n",
    "        \"초/중학생\": \"000\",\n",
    "        \"고등학생\": \"001\",\n",
    "        \"대학생 / 저학년 (1-2학년)\": \"002\",\n",
    "        \"대학생 / 고학년(3-4학년)\": \"003\",\n",
    "        \"구직자\": \"004\",\n",
    "        \"직장인\": \"005\",\n",
    "        \"자영업자\": \"006\",\n",
    "        \"프리랜서\": \"007\",\n",
    "        \"주부\": \"008\",\n",
    "        \"기타\": \"009\"\n",
    "    }\n",
    "    mbti_mapping = {\n",
    "        \"INTJ\": \"00\",\n",
    "        \"INTP\": \"01\",\n",
    "        \"ENTJ\": \"02\",\n",
    "        \"ENTP\": \"03\",\n",
    "        \"INFJ\": \"04\",\n",
    "        \"INFP\": \"05\",\n",
    "        \"ENFJ\": \"06\",\n",
    "        \"ENFP\": \"07\",\n",
    "        \"ISTJ\": \"08\",\n",
    "        \"ISFJ\": \"09\",\n",
    "        \"ESTJ\": \"10\",\n",
    "        \"ESFJ\": \"11\",\n",
    "        \"ISTP\": \"12\",\n",
    "        \"ISFP\": \"13\",\n",
    "        \"ESTP\": \"14\",\n",
    "        \"ESFP\": \"15\"\n",
    "    }\n",
    "    gender_mapping = {\n",
    "        \"남\": 0,\n",
    "        \"여\": 1\n",
    "    }\n",
    "\n",
    "    # 나이, 직업, MBTI, 성별 컬럼을 숫자 코드로 변환합니다.\n",
    "    survey_df['age'] = survey_df['age'].map(lambda x: np.random.randint(age_mapping[x][0], age_mapping[x][1] + 1))\n",
    "    survey_df['job'] = survey_df['job'].map(job_mapping)\n",
    "    survey_df['mbti'] = survey_df['mbti'].str.upper().map(mbti_mapping)\n",
    "    survey_df['gender'] = survey_df['gender'].map(gender_mapping)\n",
    "\n",
    "    # 우선순위별로 각 항목에 가중치를 적용한 값을 할당합니다.\n",
    "    work_col = []\n",
    "    edu_col = []\n",
    "    free_time_col = []\n",
    "    health_col = []\n",
    "    chores_col = []\n",
    "\n",
    "    for _, row in survey_df.iterrows():\n",
    "        work = 0\n",
    "        edu = 0\n",
    "        free_time = 0\n",
    "        health = 0\n",
    "        chores = 0\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            if row[f'priority_{i}'] == 'work':\n",
    "                work = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'edu':\n",
    "                edu = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'free_time':\n",
    "                free_time = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'health':\n",
    "                health = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'chores':\n",
    "                chores = 1 - (i - 1) * 0.25\n",
    "        \n",
    "        work_col.append(work)\n",
    "        edu_col.append(edu)\n",
    "        free_time_col.append(free_time)\n",
    "        health_col.append(health)\n",
    "        chores_col.append(chores)\n",
    "    \n",
    "    survey_df['work'] = work_col\n",
    "    survey_df['edu'] = edu_col\n",
    "    survey_df['free_time'] = free_time_col\n",
    "    survey_df['health'] = health_col\n",
    "    survey_df['chores'] = chores_col\n",
    "    \n",
    "    # 사용하지 않는 우선순위 컬럼 삭제\n",
    "    survey_df.drop(columns=['priority_1', 'priority_2', 'priority_3', 'priority_4', 'priority_5'], inplace=True)\n",
    "    \n",
    "    # 컬럼 순서 재정렬\n",
    "    survey_df = survey_df[['age', 'job', 'mbti', 'gender', 'work', 'edu', 'free_time', 'health', 'chores', 'category_else']]\n",
    "    \n",
    "    # 수정된 데이터프레임을 새로운 CSV 파일로 저장합니다.\n",
    "    survey_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_processing()  # 함수를 호출하여 변환을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원본 데이터 단순 복제로 데이터 수를 50만개로 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 복제 완료: 총 샘플 수 500000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "data = pd.read_csv(f'{file_path}survey_preprocessed.csv')\n",
    "\n",
    "# 원하는 샘플 수\n",
    "target_samples = 500000\n",
    "replication_factor = target_samples // len(data)  # 필요한 복제 횟수 계산\n",
    "additional_samples = target_samples % len(data)   # 추가로 필요한 샘플 수\n",
    "\n",
    "# 데이터 복제\n",
    "oversampled_data = pd.concat([data] * replication_factor + [data.iloc[:additional_samples]])\n",
    "\n",
    "# 결과 저장\n",
    "oversampled_data.to_csv(f'{file_path}survey_replicated.csv', index=False)\n",
    "\n",
    "print(f\"데이터 복제 완료: 총 샘플 수 {len(oversampled_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤 오버 샘플링을 통해 전체 데이터의 수를 늘리기\n",
    "\n",
    "- 단, 랜덤 오버 샘플링은 이산형 데이터에 사용이 가능\n",
    "- 따라서 '0', '0.25', '0.5', '0.75', '1'을 범주화하여 제한을 우회\n",
    "- 이후 다시 범주형 데이터를 수치로 롤백하여 원본 데이터의 형식을 유지\n",
    "- 이 외의 숫자가 혹시 포함되어 있다면 디버깅을 위해 -1로 설정\n",
    "\n",
    "- 랜덤 오버 샘플링을 위해 각 열을 독립적으로 오버 샘플링 후 다시 합쳐주는 방식 선택\n",
    "\n",
    "- 하지만 지금까지는 실패~\n",
    "    - 각 열을 독립적으로 오버 샘플링 하다보니 각 열의 인덱스를 합쳐야 NA가 없음\n",
    "    - 그러나 랜덤으로 샘플링 하기 때문에 각 파일별 인덱스 수가 달라짐\n",
    "    - 따라서 망함 :,<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "not_use"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef discretize(value):\\n    if value == 0:\\n        return \\'Very Low\\'\\n    elif value == 0.25:\\n        return \\'Low\\'\\n    elif value == 0.5:\\n        return \\'Medium\\'\\n    elif value == 0.75:\\n        return \\'High\\'\\n    elif value == 1:\\n        return \\'Very High\\'\\n    return \\'Unknown\\'\\n\\ndef continuousize(category):\\n    mapping = {\\'Very Low\\': 0, \\'Low\\': 0.25, \\'Medium\\': 0.5, \\'High\\': 0.75, \\'Very High\\': 1}\\n    return mapping.get(category, -1)\\n\\n# 데이터 로드\\noriginal_data = pd.read_csv(f\\'{file_path}survey_replicated.csv\\')\\ncategories = [\\'work\\', \\'edu\\', \\'free_time\\', \\'health\\', \\'chores\\']\\n\\n# 범주화 및 원-핫 인코딩\\nX_encoded = pd.get_dummies(original_data.drop(categories, axis=1))\\nros = RandomOverSampler(random_state=42)\\n\\n# 각 범주에 대해 오버샘플링 적용 및 저장\\nfor category in categories:\\n    y = original_data[category].apply(discretize)\\n    X_resampled, y_resampled = ros.fit_resample(X_encoded, y)\\n    y_resampled = y_resampled.apply(continuousize)\\n    df_resampled = pd.DataFrame(X_resampled, columns=X_encoded.columns)\\n    df_resampled[category] = y_resampled\\n    df_resampled.to_csv(f\\'{file_path}survey_random_oversampled_{category}.csv\\', index=False)\\n    print(f\"오버샘플링 데이터 저장 완료: survey_random_oversampled_{category}.csv, 샘플 수: {len(df_resampled)}\")\\n\\nprint(\"모든 범주에 대한 오버샘플링 데이터 저장 완료\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리 사용을 줄이기 위해 범주에 대해 개별 오버 샘플링 후 저장\n",
    "'''\n",
    "def discretize(value):\n",
    "    if value == 0:\n",
    "        return 'Very Low'\n",
    "    elif value == 0.25:\n",
    "        return 'Low'\n",
    "    elif value == 0.5:\n",
    "        return 'Medium'\n",
    "    elif value == 0.75:\n",
    "        return 'High'\n",
    "    elif value == 1:\n",
    "        return 'Very High'\n",
    "    return 'Unknown'\n",
    "\n",
    "def continuousize(category):\n",
    "    mapping = {'Very Low': 0, 'Low': 0.25, 'Medium': 0.5, 'High': 0.75, 'Very High': 1}\n",
    "    return mapping.get(category, -1)\n",
    "\n",
    "# 데이터 로드\n",
    "original_data = pd.read_csv(f'{file_path}survey_replicated.csv')\n",
    "categories = ['work', 'edu', 'free_time', 'health', 'chores']\n",
    "\n",
    "# 범주화 및 원-핫 인코딩\n",
    "X_encoded = pd.get_dummies(original_data.drop(categories, axis=1))\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# 각 범주에 대해 오버샘플링 적용 및 저장\n",
    "for category in categories:\n",
    "    y = original_data[category].apply(discretize)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_encoded, y)\n",
    "    y_resampled = y_resampled.apply(continuousize)\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X_encoded.columns)\n",
    "    df_resampled[category] = y_resampled\n",
    "    df_resampled.to_csv(f'{file_path}survey_random_oversampled_{category}.csv', index=False)\n",
    "    print(f\"오버샘플링 데이터 저장 완료: survey_random_oversampled_{category}.csv, 샘플 수: {len(df_resampled)}\")\n",
    "\n",
    "print(\"모든 범주에 대한 오버샘플링 데이터 저장 완료\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "not_use"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 데이터 로드 및 함수 정의\\ndef discretize(value):\\n    if value == 0:\\n        return \\'Very Low\\'\\n    elif value == 0.25:\\n        return \\'Low\\'\\n    elif value == 0.5:\\n        return \\'Medium\\'\\n    elif value == 0.75:\\n        return \\'High\\'\\n    elif value == 1:\\n        return \\'Very High\\'\\n    return \\'Unknown\\'\\n\\ndef continuousize(category):\\n    mapping = {\\'Very Low\\': 0, \\'Low\\': 0.25, \\'Medium\\': 0.5, \\'High\\': 0.75, \\'Very High\\': 1}\\n    return mapping.get(category, -1)\\n\\noriginal_data = pd.read_csv(f\\'{file_path}survey_replicated.csv\\')\\ncategories = [\\'work\\', \\'edu\\', \\'free_time\\', \\'health\\', \\'chores\\']\\n\\n# 범주화 및 원-핫 인코딩\\nX_encoded = pd.get_dummies(original_data.drop(categories, axis=1))\\noversampled_dataframes = []\\nros = RandomOverSampler(random_state=42)\\n\\n# 각 범주에 대해 오버샘플링 적용\\nfor category in categories:\\n    y = original_data[category].apply(discretize)\\n    X_resampled, y_resampled = ros.fit_resample(X_encoded, y)\\n    y_resampled = y_resampled.apply(continuousize)\\n    df_resampled = pd.DataFrame(X_resampled, columns=X_encoded.columns)\\n    df_resampled[category] = y_resampled\\n    oversampled_dataframes.append(df_resampled)\\n\\n# 모든 결과를 하나의 DataFrame으로 병합\\nfinal_df = oversampled_dataframes[0]\\nfor df in oversampled_dataframes[1:]:\\n    final_df = final_df.merge(df, on=list(X_encoded.columns), how=\\'inner\\')\\n\\n# 반복적 오버샘플링으로 추가 증가\\nfor _ in range(200):  # 반복 횟수에 따라 조정 가능\\n    final_df, _ = ros.fit_resample(final_df, final_df.columns)\\n\\n# 결과 저장\\nfinal_df.to_csv(f\\'{file_path}survey_random_oversampled.csv\\', index=False)\\nprint(f\"오버샘플링 데이터 저장 완료: survey_random_oversampled.csv, 샘플 수: {len(final_df)}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 열에 처리시 메모리 사용량이 지나치게 높기에 위 코드를 통해 각 범주별 개별 오버샘플링 적용 후 합치는 방식 선택\n",
    "'''\n",
    "# 데이터 로드 및 함수 정의\n",
    "def discretize(value):\n",
    "    if value == 0:\n",
    "        return 'Very Low'\n",
    "    elif value == 0.25:\n",
    "        return 'Low'\n",
    "    elif value == 0.5:\n",
    "        return 'Medium'\n",
    "    elif value == 0.75:\n",
    "        return 'High'\n",
    "    elif value == 1:\n",
    "        return 'Very High'\n",
    "    return 'Unknown'\n",
    "\n",
    "def continuousize(category):\n",
    "    mapping = {'Very Low': 0, 'Low': 0.25, 'Medium': 0.5, 'High': 0.75, 'Very High': 1}\n",
    "    return mapping.get(category, -1)\n",
    "\n",
    "original_data = pd.read_csv(f'{file_path}survey_replicated.csv')\n",
    "categories = ['work', 'edu', 'free_time', 'health', 'chores']\n",
    "\n",
    "# 범주화 및 원-핫 인코딩\n",
    "X_encoded = pd.get_dummies(original_data.drop(categories, axis=1))\n",
    "oversampled_dataframes = []\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# 각 범주에 대해 오버샘플링 적용\n",
    "for category in categories:\n",
    "    y = original_data[category].apply(discretize)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_encoded, y)\n",
    "    y_resampled = y_resampled.apply(continuousize)\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X_encoded.columns)\n",
    "    df_resampled[category] = y_resampled\n",
    "    oversampled_dataframes.append(df_resampled)\n",
    "\n",
    "# 모든 결과를 하나의 DataFrame으로 병합\n",
    "final_df = oversampled_dataframes[0]\n",
    "for df in oversampled_dataframes[1:]:\n",
    "    final_df = final_df.merge(df, on=list(X_encoded.columns), how='inner')\n",
    "\n",
    "# 반복적 오버샘플링으로 추가 증가\n",
    "for _ in range(200):  # 반복 횟수에 따라 조정 가능\n",
    "    final_df, _ = ros.fit_resample(final_df, final_df.columns)\n",
    "\n",
    "# 결과 저장\n",
    "final_df.to_csv(f'{file_path}survey_random_oversampled.csv', index=False)\n",
    "print(f\"오버샘플링 데이터 저장 완료: survey_random_oversampled.csv, 샘플 수: {len(final_df)}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "not_use"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport glob\\nimport os\\n\\n# 모든 CSV 파일의 경로를 리스트로 로드\\ncsv_files = glob.glob(os.path.join(file_path, \\'survey_random*.csv\\'))\\n\\n# CSV 파일 경로 출력 (디버깅용)\\nprint(\"CSV files found:\", csv_files)\\n\\n# CSV 파일이 존재하는지 확인\\nif not csv_files:\\n    raise ValueError(\"No CSV files found in the specified directory.\")\\n\\n# 모든 CSV 파일을 읽어 하나의 데이터프레임으로 병합\\ndataframes = []\\nfor file in csv_files:\\n    try:\\n        df = pd.read_csv(file)\\n        dataframes.append(df)\\n    except Exception as e:\\n        print(f\"Error reading {file}: {e}\")\\n\\n# 데이터프레임 병합\\nif dataframes:\\n    merged_dataframe = pd.concat(dataframes, ignore_index=True)\\n    # 합쳐진 데이터프레임을 새로운 CSV 파일로 저장\\n    merged_dataframe.to_csv(f\"{file_path}merged_survey_data.csv\", index=False)\\nelse:\\n    raise ValueError(\"No valid CSV files to concatenate.\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 모든 CSV 파일의 경로를 리스트로 로드\n",
    "csv_files = glob.glob(os.path.join(file_path, 'survey_random*.csv'))\n",
    "\n",
    "# CSV 파일 경로 출력 (디버깅용)\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "# CSV 파일이 존재하는지 확인\n",
    "if not csv_files:\n",
    "    raise ValueError(\"No CSV files found in the specified directory.\")\n",
    "\n",
    "# 모든 CSV 파일을 읽어 하나의 데이터프레임으로 병합\n",
    "dataframes = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# 데이터프레임 병합\n",
    "if dataframes:\n",
    "    merged_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "    # 합쳐진 데이터프레임을 새로운 CSV 파일로 저장\n",
    "    merged_dataframe.to_csv(f\"{file_path}merged_survey_data.csv\", index=False)\n",
    "else:\n",
    "    raise ValueError(\"No valid CSV files to concatenate.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순 오버 샘플링을 통해 늘어난 데이터 수를 바탕으로 smote 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "original_data = pd.read_csv(f'{file_path}survey_replicated.csv')\n",
    "\n",
    "# 데이터 스케일링 및 클러스터링\n",
    "scaler = StandardScaler()\n",
    "y_scaled = scaler.fit_transform(original_data[['work', 'edu', 'free_time', 'health', 'chores']])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(y_scaled)\n",
    "\n",
    "\n",
    "# SMOTE 적용 (연속형 데이터 포함)\n",
    "# n_neighbors 값 조정: 가장 작은 클러스터의 크기보다 작게 설정\n",
    "min_cluster_size = min(pd.Series(clusters).value_counts())\n",
    "n_neighbors = max(min(2, min_cluster_size - 1), 1)  # 최소 1, 최대 (가장 작은 클러스터 크기 - 1) 사이\n",
    "smote = SMOTE(random_state=42, k_neighbors=n_neighbors)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(original_data, clusters)\n",
    "\n",
    "# 연속형 데이터 복원: 각 클러스터의 중심을 사용하여 연속형 데이터를 복원\n",
    "cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "oversampled_y = [cluster_centers[cluster] for cluster in clusters_resampled]\n",
    "\n",
    "# 오버샘플링된 데이터 프레임 생성\n",
    "oversampled_df = pd.DataFrame(X_resampled, columns=original_data.columns)\n",
    "oversampled_df[['work', 'edu', 'free_time', 'health', 'chores']] = pd.DataFrame(oversampled_y, columns=['work', 'edu', 'free_time', 'health', 'chores'])\n",
    "\n",
    "# 결과 저장 및 출력\n",
    "oversampled_df.to_csv(f'{file_path}survey_oversampled.csv', index=False)\n",
    "print(\"오버샘플링 데이터 저장 완료: survey_oversampled.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오버 샘플링 된 데이터들을 정제하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 오버샘플링된 데이터 로드\\noversampled_data = pd.read_csv(f\\'{file_path}survey_oversampled.csv\\')\\n\\n# \\'job\\' 관련 열 추출 및 변환\\njob_columns = [col for col in oversampled_data.columns if col.startswith(\\'job_\\')]\\noversampled_data[\\'job\\'] = oversampled_data[job_columns].idxmax(axis=1).apply(lambda x: x.split(\\'_\\')[1] if pd.notna(x) else None)\\n\\n# \\'mbti\\' 관련 열 추출 및 변환\\nmbti_columns = [col for col in oversampled_data.columns if col.startswith(\\'mbti_\\')]\\noversampled_data[\\'mbti\\'] = oversampled_data[mbti_columns].idxmax(axis=1).apply(lambda x: x.split(\\'_\\')[1] if pd.notna(x) else None)\\n\\n# 불필요한 원-핫 인코딩 열 제거\\noversampled_data.drop(columns=job_columns + mbti_columns, inplace=True)\\n\\n# 결과 저장\\noversampled_data.to_csv(f\\'{file_path}survey_oversampled_fixed.csv\\', index=False)\\n\\nprint(\"데이터 업데이트 완료: survey_oversampled_fixed.csv\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 오버샘플링된 데이터 로드\n",
    "oversampled_data = pd.read_csv(f'{file_path}survey_oversampled.csv')\n",
    "\n",
    "# 'job' 관련 열 추출 및 변환\n",
    "job_columns = [col for col in oversampled_data.columns if col.startswith('job_')]\n",
    "oversampled_data['job'] = oversampled_data[job_columns].idxmax(axis=1).apply(lambda x: x.split('_')[1] if pd.notna(x) else None)\n",
    "\n",
    "# 'mbti' 관련 열 추출 및 변환\n",
    "mbti_columns = [col for col in oversampled_data.columns if col.startswith('mbti_')]\n",
    "oversampled_data['mbti'] = oversampled_data[mbti_columns].idxmax(axis=1).apply(lambda x: x.split('_')[1] if pd.notna(x) else None)\n",
    "\n",
    "# 불필요한 원-핫 인코딩 열 제거\n",
    "oversampled_data.drop(columns=job_columns + mbti_columns, inplace=True)\n",
    "\n",
    "# 결과 저장\n",
    "oversampled_data.to_csv(f'{file_path}survey_oversampled_fixed.csv', index=False)\n",
    "\n",
    "print(\"데이터 업데이트 완료: survey_oversampled_fixed.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 마지막으로 value 수정\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fix_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124msurvey_oversampled.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 열 순서 재배열\u001b[39;00m\n\u001b[0;32m      5\u001b[0m columns_ordered \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmbti\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfree_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhealth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_else\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# 마지막으로 value 수정\n",
    "fix_data = pd.read_csv(f'{file_path}survey_oversampled.csv')\n",
    "\n",
    "# 열 순서 재배열\n",
    "columns_ordered = ['age', 'gender', 'job', 'mbti', 'work', 'edu', 'free_time', 'health', 'chores']\n",
    "fix_data = fix_data[columns_ordered]\n",
    "\n",
    "fix_data.to_csv(f'{file_path}survey_data.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "      <td>600003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.799424</td>\n",
       "      <td>0.589380</td>\n",
       "      <td>4.347768</td>\n",
       "      <td>7.354457</td>\n",
       "      <td>0.599243</td>\n",
       "      <td>0.422304</td>\n",
       "      <td>0.496634</td>\n",
       "      <td>0.684763</td>\n",
       "      <td>0.196383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.351794</td>\n",
       "      <td>0.491947</td>\n",
       "      <td>1.546530</td>\n",
       "      <td>4.525648</td>\n",
       "      <td>0.258853</td>\n",
       "      <td>0.157070</td>\n",
       "      <td>0.243146</td>\n",
       "      <td>0.262233</td>\n",
       "      <td>0.182342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.263885</td>\n",
       "      <td>0.152780</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.263885</td>\n",
       "      <td>0.152780</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.011364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.819440</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.791668</td>\n",
       "      <td>0.636362</td>\n",
       "      <td>0.670454</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.444452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.791668</td>\n",
       "      <td>0.636362</td>\n",
       "      <td>0.670454</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.444452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age         gender            job           mbti  \\\n",
       "count  600003.000000  600003.000000  600003.000000  600003.000000   \n",
       "mean       28.799424       0.589380       4.347768       7.354457   \n",
       "std         7.351794       0.491947       1.546530       4.525648   \n",
       "min        12.000000       0.000000       0.000000       0.000000   \n",
       "25%        25.000000       0.000000       3.000000       4.000000   \n",
       "50%        27.000000       1.000000       4.000000       7.000000   \n",
       "75%        32.000000       1.000000       5.000000      12.000000   \n",
       "max        45.000000       1.000000       8.000000      15.000000   \n",
       "\n",
       "                work            edu      free_time         health  \\\n",
       "count  600003.000000  600003.000000  600003.000000  600003.000000   \n",
       "mean        0.599243       0.422304       0.496634       0.684763   \n",
       "std         0.258853       0.157070       0.243146       0.262233   \n",
       "min         0.233333       0.263885       0.152780       0.318182   \n",
       "25%         0.233333       0.263885       0.152780       0.318182   \n",
       "50%         0.772729       0.366667       0.666667       0.819440   \n",
       "75%         0.791668       0.636362       0.670454       0.916667   \n",
       "max         0.791668       0.636362       0.670454       0.916667   \n",
       "\n",
       "              chores  \n",
       "count  600003.000000  \n",
       "mean        0.196383  \n",
       "std         0.182342  \n",
       "min         0.011364  \n",
       "25%         0.011364  \n",
       "50%         0.133333  \n",
       "75%         0.444452  \n",
       "max         0.444452  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플링 이후 스케일링 방법으로 데이터 생성\n",
    "\n",
    "- 랜덤 선택 후 증식 방법으로 설문 조사 분포를 유지하며 데이터 증식\n",
    "- 랜덤 샘플링 이후 smote 적용하여 데이터 불균형 해소\n",
    "- 이후 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오버샘플링 데이터 저장 완료: ./refer/output/survey_oversampled_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = './refer/output/'\n",
    "data_path = f'{file_path}survey.csv'\n",
    "output_path = f'{file_path}survey_oversampled_v2.csv'\n",
    "preprocessed_output_path = f'{file_path}survey_preprocessed_v2.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "columns_to_keep = [\n",
    "    \"설문자의 나이(만)는 어떻게 되십니까?\",\n",
    "    \"설문자의 해당사항을 체크해주세요.\", # 직업\n",
    "    \"설문자의 MBTI는 무엇입니까?\",\n",
    "    \"설문자의 성별은 어떻게 되십니까?\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\"\n",
    "]\n",
    "survey_df = survey_df[columns_to_keep]\n",
    "\n",
    "# 오버샘플링을 수행하는 함수\n",
    "def oversample_data(df, target_size=700000):\n",
    "    current_size = len(df)\n",
    "    if (target_size - current_size) > current_size:\n",
    "        oversample_count = target_size - current_size\n",
    "        oversampled_df = resample(df, replace=True, n_samples=oversample_count, random_state=42)\n",
    "        return pd.concat([df, oversampled_df], axis=0)\n",
    "    else:\n",
    "        return resample(df, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# 데이터를 70만 개로 오버샘플링\n",
    "oversampled_survey_df = oversample_data(survey_df, target_size=700000)\n",
    "\n",
    "# 더미 변수 생성\n",
    "categorical_features = columns_to_keep\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 전처리 파이프라인\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# 데이터 변환\n",
    "X = pipeline.fit_transform(oversampled_survey_df)\n",
    "\n",
    "# KMeans 클러스터링\n",
    "# 5순위 특성값에 맞게 클러스터 5로 설정\n",
    "# 5개로 쪼개진 클러스터에 각각 smote 적용하여 데이터 다양성 높이면서 클러스터 특성 유지\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(X, clusters)\n",
    "\n",
    "# 더미 변수를 원래 값으로 변환\n",
    "inverse_transformer = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "oversampled_df = pd.DataFrame(inverse_transformer.inverse_transform(X_resampled), columns=columns_to_keep)\n",
    "\n",
    "# 원래 survey_df의 인덱스를 저장\n",
    "original_index = survey_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오버샘플링 데이터 저장 완료: ./refer/output/survey_oversampled_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# oversampled_df에서 원래 oversampled_survey_df와 동일한 행을 제거\n",
    "unique_oversampled_df = oversampled_df.merge(oversampled_survey_df.drop_duplicates(), on=columns_to_keep, how='left', indicator=True)\n",
    "unique_oversampled_df = unique_oversampled_df[unique_oversampled_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "# 최종 결과 저장\n",
    "unique_oversampled_df.to_csv(output_path, index=False)\n",
    "print(f\"오버샘플링 데이터 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>설문자의 나이(만)는 어떻게 되십니까?</th>\n",
       "      <th>설문자의 해당사항을 체크해주세요.</th>\n",
       "      <th>설문자의 MBTI는 무엇입니까?</th>\n",
       "      <th>설문자의 성별은 어떻게 되십니까?</th>\n",
       "      <th>본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]</th>\n",
       "      <th>본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]</th>\n",
       "      <th>본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]</th>\n",
       "      <th>본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]</th>\n",
       "      <th>본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>구직자</td>\n",
       "      <td>intj</td>\n",
       "      <td>남</td>\n",
       "      <td>건강</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>업무</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>구직자</td>\n",
       "      <td>intj</td>\n",
       "      <td>남</td>\n",
       "      <td>건강</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>집안일</td>\n",
       "      <td>업무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>대학생 / 고학년(3-4학년)</td>\n",
       "      <td>ESFP</td>\n",
       "      <td>여</td>\n",
       "      <td>업무</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>건강</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20~24세</td>\n",
       "      <td>대학생 / 고학년(3-4학년)</td>\n",
       "      <td>intp</td>\n",
       "      <td>남</td>\n",
       "      <td>업무</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>건강</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>구직자</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>남</td>\n",
       "      <td>건강</td>\n",
       "      <td>집안일</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>업무</td>\n",
       "      <td>여가시간</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084885</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>구직자</td>\n",
       "      <td>INFP</td>\n",
       "      <td>남</td>\n",
       "      <td>건강</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>업무</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>업무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084886</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>대학생 / 고학년(3-4학년)</td>\n",
       "      <td>isfj</td>\n",
       "      <td>남</td>\n",
       "      <td>업무</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>건강</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084887</th>\n",
       "      <td>20~24세</td>\n",
       "      <td>대학생 / 저학년 (1-2학년)</td>\n",
       "      <td>Estp</td>\n",
       "      <td>여</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>업무</td>\n",
       "      <td>건강</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084888</th>\n",
       "      <td>25~30세</td>\n",
       "      <td>구직자</td>\n",
       "      <td>INFP</td>\n",
       "      <td>남</td>\n",
       "      <td>건강</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>업무</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>업무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084889</th>\n",
       "      <td>20~24세</td>\n",
       "      <td>대학생 / 고학년(3-4학년)</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>여</td>\n",
       "      <td>학업 및 자기계발</td>\n",
       "      <td>건강</td>\n",
       "      <td>업무</td>\n",
       "      <td>여가시간</td>\n",
       "      <td>집안일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084890 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        설문자의 나이(만)는 어떻게 되십니까? 설문자의 해당사항을 체크해주세요. 설문자의 MBTI는 무엇입니까?  \\\n",
       "0                      25~30세                구직자              intj   \n",
       "1                      25~30세                구직자              intj   \n",
       "2                      25~30세   대학생 / 고학년(3-4학년)              ESFP   \n",
       "3                      20~24세   대학생 / 고학년(3-4학년)              intp   \n",
       "4                      25~30세                구직자              ISTP   \n",
       "...                       ...                ...               ...   \n",
       "1084885                25~30세                구직자              INFP   \n",
       "1084886                25~30세   대학생 / 고학년(3-4학년)              isfj   \n",
       "1084887                20~24세  대학생 / 저학년 (1-2학년)              Estp   \n",
       "1084888                25~30세                구직자              INFP   \n",
       "1084889                20~24세   대학생 / 고학년(3-4학년)              INTJ   \n",
       "\n",
       "        설문자의 성별은 어떻게 되십니까?  \\\n",
       "0                        남   \n",
       "1                        남   \n",
       "2                        여   \n",
       "3                        남   \n",
       "4                        남   \n",
       "...                    ...   \n",
       "1084885                  남   \n",
       "1084886                  남   \n",
       "1084887                  여   \n",
       "1084888                  남   \n",
       "1084889                  여   \n",
       "\n",
       "        본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]  \\\n",
       "0                                                       건강                  \n",
       "1                                                       건강                  \n",
       "2                                                       업무                  \n",
       "3                                                       업무                  \n",
       "4                                                       건강                  \n",
       "...                                                    ...                  \n",
       "1084885                                                 건강                  \n",
       "1084886                                                 업무                  \n",
       "1084887                                               여가시간                  \n",
       "1084888                                                 건강                  \n",
       "1084889                                          학업 및 자기계발                  \n",
       "\n",
       "        본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]  \\\n",
       "0                                                     여가시간                  \n",
       "1                                                     여가시간                  \n",
       "2                                                학업 및 자기계발                  \n",
       "3                                                     여가시간                  \n",
       "4                                                      집안일                  \n",
       "...                                                    ...                  \n",
       "1084885                                          학업 및 자기계발                  \n",
       "1084886                                          학업 및 자기계발                  \n",
       "1084887                                          학업 및 자기계발                  \n",
       "1084888                                          학업 및 자기계발                  \n",
       "1084889                                                 건강                  \n",
       "\n",
       "        본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]  \\\n",
       "0                                                학업 및 자기계발                  \n",
       "1                                                학업 및 자기계발                  \n",
       "2                                                     여가시간                  \n",
       "3                                                학업 및 자기계발                  \n",
       "4                                                학업 및 자기계발                  \n",
       "...                                                    ...                  \n",
       "1084885                                                 업무                  \n",
       "1084886                                                 건강                  \n",
       "1084887                                                 업무                  \n",
       "1084888                                                 업무                  \n",
       "1084889                                                 업무                  \n",
       "\n",
       "        본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]  \\\n",
       "0                                                       업무                  \n",
       "1                                                      집안일                  \n",
       "2                                                       건강                  \n",
       "3                                                       건강                  \n",
       "4                                                       업무                  \n",
       "...                                                    ...                  \n",
       "1084885                                               여가시간                  \n",
       "1084886                                               여가시간                  \n",
       "1084887                                                 건강                  \n",
       "1084888                                               여가시간                  \n",
       "1084889                                               여가시간                  \n",
       "\n",
       "        본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]  \n",
       "0                                                      집안일                 \n",
       "1                                                       업무                 \n",
       "2                                                      집안일                 \n",
       "3                                                      집안일                 \n",
       "4                                                     여가시간                 \n",
       "...                                                    ...                 \n",
       "1084885                                                 업무                 \n",
       "1084886                                                집안일                 \n",
       "1084887                                                집안일                 \n",
       "1084888                                                 업무                 \n",
       "1084889                                                집안일                 \n",
       "\n",
       "[1084890 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin 결과를 얻습니다\n",
    "isin_result = oversampled_survey_df.isin(oversampled_df)\n",
    "\n",
    "# 각 행의 모든 컬럼이 True인 행을 선택합니다\n",
    "all_true_rows = isin_result.all(axis=1)\n",
    "\n",
    "# True인 행만 필터링합니다\n",
    "true_rows_df = oversampled_survey_df[all_true_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = oversampled_survey_df.isin(oversampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모든 행에 대해 isin을 적용하여 True/False 결과를 얻습니다\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m isin_result \u001b[38;5;241m=\u001b[39m \u001b[43moversampled_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moversampled_survey_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# True인 행들을 제외하고 unique_oversampled_df를 얻습니다\u001b[39;00m\n\u001b[0;32m      5\u001b[0m unique_oversampled_df_1 \u001b[38;5;241m=\u001b[39m oversampled_df[\u001b[38;5;241m~\u001b[39misin_result]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10360\u001b[0m )\n\u001b[1;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모든 행에 대해 isin을 적용하여 True/False 결과를 얻습니다\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m isin_result \u001b[38;5;241m=\u001b[39m oversampled_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39misin(\u001b[43moversampled_survey_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mall(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# True인 행들을 제외하고 unique_oversampled_df를 얻습니다\u001b[39;00m\n\u001b[0;32m      5\u001b[0m unique_oversampled_df_1 \u001b[38;5;241m=\u001b[39m oversampled_df[\u001b[38;5;241m~\u001b[39misin_result]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:2166\u001b[0m, in \u001b[0;36mDataFrame.to_dict\u001b[1;34m(self, orient, into, index)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;124;03mConvert the DataFrame to a dictionary.\u001b[39;00m\n\u001b[0;32m   2065\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2162\u001b[0m \u001b[38;5;124;03m defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\u001b[39;00m\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_dict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_dict\n\u001b[1;32m-> 2166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\methods\\to_dict.py:171\u001b[0m, in \u001b[0;36mto_dict\u001b[1;34m(df, orient, into, index)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     object_dtype_indices_as_set: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(box_native_indices)\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minto_c\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaybe_box_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbox_na_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobject_dtype_indices_as_set\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaybe_box_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m     data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_create_data_for_split_and_tight_to_dict(\n\u001b[0;32m    183\u001b[0m         are_all_object_dtype_cols, box_native_indices\n\u001b[0;32m    184\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\methods\\to_dict.py:174\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     object_dtype_indices_as_set: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(box_native_indices)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m into_c(\n\u001b[0;32m    172\u001b[0m         (\n\u001b[0;32m    173\u001b[0m             k,\n\u001b[1;32m--> 174\u001b[0m             \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaybe_box_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbox_na_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m object_dtype_indices_as_set\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(maybe_box_native, v\u001b[38;5;241m.\u001b[39mto_numpy())),\n\u001b[0;32m    177\u001b[0m         )\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (k, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m     data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_create_data_for_split_and_tight_to_dict(\n\u001b[0;32m    183\u001b[0m         are_all_object_dtype_cols, box_native_indices\n\u001b[0;32m    184\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:195\u001b[0m, in \u001b[0;36mmaybe_box_native\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_box_native\u001b[39m(value: Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NAType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Scalar \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NAType:\n\u001b[0;32m    184\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    If passed a scalar cast the scalar to a python native type.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    scalar or Series\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    196\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(value)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_integer(value):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모든 행에 대해 isin을 적용하여 True/False 결과를 얻습니다\n",
    "isin_result = oversampled_df.apply(lambda row: row.isin(oversampled_survey_df.to_dict(orient='list')).all(), axis=1)\n",
    "\n",
    "# True인 행들을 제외하고 unique_oversampled_df를 얻습니다\n",
    "unique_oversampled_df_1 = oversampled_df[~isin_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 105. GiB for an array with shape (14114693089,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모든 열을 기준으로 df1과 df를 비교하여 df1에서 df를 제거\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_diff \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43moversampled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moversampled_survey_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_merge == \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_only\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_merge\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mget_join_indexers_non_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1801\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1799\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39minner_join(lkey, rkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1801\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_outer_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lidx, ridx\n",
      "File \u001b[1;32mjoin.pyx:188\u001b[0m, in \u001b[0;36mpandas._libs.join.full_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 105. GiB for an array with shape (14114693089,) and data type int64"
     ]
    }
   ],
   "source": [
    "# 모든 열을 기준으로 df1과 df를 비교하여 df1에서 df를 제거\n",
    "df_diff = pd.merge(oversampled_df, oversampled_survey_df, how='outer', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_oversampled_df_fix = oversampled_df.loc[~oversampled_df.index.isin(true_rows_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1084835 entries, 55 to 1084889\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                                             Non-Null Count    Dtype \n",
      "---  ------                                                             --------------    ----- \n",
      " 0   설문자의 나이(만)는 어떻게 되십니까?                                              1084835 non-null  object\n",
      " 1   설문자의 해당사항을 체크해주세요.                                                 1084835 non-null  object\n",
      " 2   설문자의 MBTI는 무엇입니까?                                                  1084835 non-null  object\n",
      " 3   설문자의 성별은 어떻게 되십니까?                                                 1084835 non-null  object\n",
      " 4   본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]  1084835 non-null  object\n",
      " 5   본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]  1084835 non-null  object\n",
      " 6   본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]  1084835 non-null  object\n",
      " 7   본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]  1084835 non-null  object\n",
      " 8   본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]  1084835 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 82.8+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터가 저장되었습니다: ./refer/output/survey_preprocessed_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def survey_processing(file_path, output_path):\n",
    "    # CSV 파일을 로드\n",
    "    survey_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 우선순위에 대한 가중치 매핑을 정의\n",
    "    priority_weights = {\n",
    "        \"건강\": \"health\",\n",
    "        \"여가시간\": \"free_time\",\n",
    "        \"학업 및 자기계발\": \"edu\",\n",
    "        \"업무\": \"work\",\n",
    "        \"집안일\": \"chores\",\n",
    "        None: \"category_else\"\n",
    "    }\n",
    "    \n",
    "    # 각 우선순위 컬럼에 대해 가중치를 적용\n",
    "    for i in range(1, 6):\n",
    "        column_name = f\"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [{i} 순위]\"\n",
    "        survey_df[column_name] = survey_df[column_name].map(priority_weights)\n",
    "    \n",
    "    # 필요한 컬럼들만 선택하고 리네임\n",
    "    columns_to_keep = [\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\"\n",
    "    ]\n",
    "    \n",
    "    survey_df = survey_df[columns_to_keep]\n",
    "    \n",
    "    # 컬럼명을 변환\n",
    "    column_mapping = {\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\": \"age\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\": \"job\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\": \"mbti\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\": \"gender\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\": \"priority_1\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\": \"priority_2\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\": \"priority_3\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\": \"priority_4\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\": \"priority_5\"\n",
    "    }\n",
    "    \n",
    "    survey_df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    # 새로운 컬럼 'category_else'를 추가하고 모든 값을 0으로 설정\n",
    "    survey_df[\"category_else\"] = 0\n",
    "    \n",
    "    # 나이, 직업, MBTI 컬럼을 숫자 코드로 변환\n",
    "    age_mapping = {\n",
    "        \"0~14세\": (0, 14),\n",
    "        \"15~19세\": (15, 19),\n",
    "        \"20~24세\": (20, 24),\n",
    "        \"25~30세\": (25, 30),\n",
    "        \"31세 이상\": (31, 45)\n",
    "    }\n",
    "    job_mapping = {\n",
    "        \"초/중학생\": \"000\",\n",
    "        \"고등학생\": \"001\",\n",
    "        \"대학생 / 저학년 (1-2학년)\": \"002\",\n",
    "        \"대학생 / 고학년(3-4학년)\": \"003\",\n",
    "        \"구직자\": \"004\",\n",
    "        \"직장인\": \"005\",\n",
    "        \"자영업자\": \"006\",\n",
    "        \"프리랜서\": \"007\",\n",
    "        \"주부\": \"008\",\n",
    "        \"기타\": \"009\"\n",
    "    }\n",
    "    mbti_mapping = {\n",
    "        \"INTJ\": \"00\",\n",
    "        \"INTP\": \"01\",\n",
    "        \"ENTJ\": \"02\",\n",
    "        \"ENTP\": \"03\",\n",
    "        \"INFJ\": \"04\",\n",
    "        \"INFP\": \"05\",\n",
    "        \"ENFJ\": \"06\",\n",
    "        \"ENFP\": \"07\",\n",
    "        \"ISTJ\": \"08\",\n",
    "        \"ISFJ\": \"09\",\n",
    "        \"ESTJ\": \"10\",\n",
    "        \"ESFJ\": \"11\",\n",
    "        \"ISTP\": \"12\",\n",
    "        \"ISFP\": \"13\",\n",
    "        \"ESTP\": \"14\",\n",
    "        \"ESFP\": \"15\"\n",
    "    }\n",
    "    gender_mapping = {\n",
    "        \"남\": 0,\n",
    "        \"여\": 1\n",
    "    }\n",
    "\n",
    "    # 나이, 직업, MBTI, 성별 컬럼을 숫자 코드로 변환\n",
    "    survey_df['age'] = survey_df['age'].map(lambda x: np.random.randint(age_mapping[x][0], age_mapping[x][1] + 1))\n",
    "    survey_df['job'] = survey_df['job'].map(job_mapping)\n",
    "    survey_df['mbti'] = survey_df['mbti'].str.upper().map(mbti_mapping)\n",
    "    survey_df['gender'] = survey_df['gender'].map(gender_mapping)\n",
    "\n",
    "    # 우선순위별로 각 항목에 가중치를 적용한 값을 할당\n",
    "    work_col = []\n",
    "    edu_col = []\n",
    "    free_time_col = []\n",
    "    health_col = []\n",
    "    chores_col = []\n",
    "\n",
    "    for _, row in survey_df.iterrows():\n",
    "        work = 0\n",
    "        edu = 0\n",
    "        free_time = 0\n",
    "        health = 0\n",
    "        chores = 0\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            if row[f'priority_{i}'] == 'work':\n",
    "                work = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'edu':\n",
    "                edu = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'free_time':\n",
    "                free_time = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'health':\n",
    "                health = 1 - (i - 1) * 0.25\n",
    "            elif row[f'priority_{i}'] == 'chores':\n",
    "                chores = 1 - (i - 1) * 0.25\n",
    "        \n",
    "        work_col.append(work)\n",
    "        edu_col.append(edu)\n",
    "        free_time_col.append(free_time)\n",
    "        health_col.append(health)\n",
    "        chores_col.append(chores)\n",
    "    \n",
    "    survey_df['work'] = work_col\n",
    "    survey_df['edu'] = edu_col\n",
    "    survey_df['free_time'] = free_time_col\n",
    "    survey_df['health'] = health_col\n",
    "    survey_df['chores'] = chores_col\n",
    "    \n",
    "    # 사용하지 않는 우선순위 컬럼 삭제\n",
    "    survey_df.drop(columns=['priority_1', 'priority_2', 'priority_3', 'priority_4', 'priority_5'], inplace=True)\n",
    "    \n",
    "    # 컬럼 순서 재정렬\n",
    "    survey_df = survey_df[['age', 'job', 'mbti', 'gender', 'work', 'edu', 'free_time', 'health', 'chores', 'category_else']]\n",
    "    \n",
    "    # 수정된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "    survey_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 오버샘플링된 데이터를 전처리\n",
    "survey_processing(f'{file_path}survey_oversampled_v2.csv', preprocessed_output_path)\n",
    "print(f\"전처리된 데이터가 저장되었습니다: {preprocessed_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_processing(f'{file_path}survey.csv', f'{file_path}survey_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_pro = pd.read_csv(f'{file_path}survey_preprocessed_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_basic = pd.read_csv(f'{file_path}survey_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>gender</th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "      <th>category_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.381818</td>\n",
       "      <td>4.327273</td>\n",
       "      <td>7.381818</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.440909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.352284</td>\n",
       "      <td>1.564118</td>\n",
       "      <td>4.572425</td>\n",
       "      <td>0.494413</td>\n",
       "      <td>0.349783</td>\n",
       "      <td>0.329715</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.342549</td>\n",
       "      <td>0.255578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age        job       mbti     gender       work        edu  \\\n",
       "count  55.000000  55.000000  55.000000  55.000000  55.000000  55.000000   \n",
       "mean   29.381818   4.327273   7.381818   0.600000   0.631818   0.440909   \n",
       "std     6.352284   1.564118   4.572425   0.494413   0.349783   0.329715   \n",
       "min    14.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%    25.000000   3.000000   4.000000   0.000000   0.375000   0.250000   \n",
       "50%    28.000000   4.000000   7.000000   1.000000   0.750000   0.500000   \n",
       "75%    33.500000   5.000000  12.000000   1.000000   1.000000   0.750000   \n",
       "max    44.000000   8.000000  15.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "       free_time     health     chores  category_else  \n",
       "count  55.000000  55.000000  55.000000           55.0  \n",
       "mean    0.500000   0.645455   0.186364            0.0  \n",
       "std     0.333333   0.342549   0.255578            0.0  \n",
       "min     0.000000   0.000000   0.000000            0.0  \n",
       "25%     0.250000   0.250000   0.000000            0.0  \n",
       "50%     0.500000   0.750000   0.000000            0.0  \n",
       "75%     0.750000   1.000000   0.250000            0.0  \n",
       "max     1.000000   1.000000   0.750000            0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_basic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>gender</th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "      <th>category_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1.084890e+06</td>\n",
       "      <td>1084890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.842276e+01</td>\n",
       "      <td>4.287457e+00</td>\n",
       "      <td>7.397241e+00</td>\n",
       "      <td>5.453788e-01</td>\n",
       "      <td>5.945515e-01</td>\n",
       "      <td>4.500477e-01</td>\n",
       "      <td>5.055029e-01</td>\n",
       "      <td>6.768728e-01</td>\n",
       "      <td>1.728809e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.661775e+00</td>\n",
       "      <td>1.526338e+00</td>\n",
       "      <td>4.583843e+00</td>\n",
       "      <td>4.979367e-01</td>\n",
       "      <td>3.437593e-01</td>\n",
       "      <td>3.270557e-01</td>\n",
       "      <td>3.298051e-01</td>\n",
       "      <td>3.414033e-01</td>\n",
       "      <td>2.333875e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.500000e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           job          mbti        gender          work  \\\n",
       "count  1.084890e+06  1.084890e+06  1.084890e+06  1.084890e+06  1.084890e+06   \n",
       "mean   2.842276e+01  4.287457e+00  7.397241e+00  5.453788e-01  5.945515e-01   \n",
       "std    6.661775e+00  1.526338e+00  4.583843e+00  4.979367e-01  3.437593e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.500000e+01  3.000000e+00  4.000000e+00  0.000000e+00  2.500000e-01   \n",
       "50%    2.800000e+01  4.000000e+00  7.000000e+00  1.000000e+00  7.500000e-01   \n",
       "75%    3.000000e+01  5.000000e+00  1.200000e+01  1.000000e+00  1.000000e+00   \n",
       "max    4.500000e+01  8.000000e+00  1.500000e+01  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                edu     free_time        health        chores  category_else  \n",
       "count  1.084890e+06  1.084890e+06  1.084890e+06  1.084890e+06      1084890.0  \n",
       "mean   4.500477e-01  5.055029e-01  6.768728e-01  1.728809e-01            0.0  \n",
       "std    3.270557e-01  3.298051e-01  3.414033e-01  2.333875e-01            0.0  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00            0.0  \n",
       "25%    2.500000e-01  2.500000e-01  2.500000e-01  0.000000e+00            0.0  \n",
       "50%    5.000000e-01  5.000000e-01  7.500000e-01  0.000000e+00            0.0  \n",
       "75%    7.500000e-01  7.500000e-01  1.000000e+00  2.500000e-01            0.0  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  7.500000e-01            0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_pro.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 불러옵니다.\n",
    "pre_path = f'{file_path}survey_preprocessed_v2.csv'\n",
    "data = pd.read_csv(pre_path)\n",
    "\n",
    "# 동일한 행을 찾기 위해 필요한 열을 지정합니다.\n",
    "specified_columns = ['job', 'mbti', 'gender', 'work', 'edu', 'free_time', 'health', 'chores', 'category_else']\n",
    "\n",
    "# 지정된 열에 대해 중복된 행을 찾습니다.\n",
    "identical_rows = data.duplicated(subset=specified_columns, keep=False)\n",
    "\n",
    "# 중복된 행만 추출합니다.\n",
    "duplicate_data = data[identical_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>gender</th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "      <th>category_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084885</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084886</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084887</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084888</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084889</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1084890 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  job  mbti  gender  work   edu  free_time  health  chores  \\\n",
       "0         30    4     0       0  0.25  0.50       0.75    1.00    0.00   \n",
       "1         27    4     0       0  0.00  0.50       0.75    1.00    0.25   \n",
       "2         30    3    15       1  1.00  0.75       0.50    0.25    0.00   \n",
       "3         23    3     1       0  1.00  0.50       0.75    0.25    0.00   \n",
       "4         28    4    12       0  0.25  0.50       0.00    1.00    0.75   \n",
       "...      ...  ...   ...     ...   ...   ...        ...     ...     ...   \n",
       "1084885   29    4     5       0  0.00  0.75       0.25    1.00    0.00   \n",
       "1084886   30    3     9       0  1.00  0.75       0.25    0.50    0.00   \n",
       "1084887   21    2    14       1  0.50  0.75       1.00    0.25    0.00   \n",
       "1084888   25    4     5       0  0.00  0.75       0.25    1.00    0.00   \n",
       "1084889   24    3     0       1  0.50  1.00       0.25    0.75    0.00   \n",
       "\n",
       "         category_else  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1084885              0  \n",
       "1084886              0  \n",
       "1084887              0  \n",
       "1084888              0  \n",
       "1084889              0  \n",
       "\n",
       "[1084890 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 중복된 행 중에서 고유한 조합을 찾습니다.\n",
    "unique_combinations = duplicate_data[specified_columns].drop_duplicates()\n",
    "\n",
    "# 고유한 조합을 기준으로 50개의 행을 무작위로 선택합니다.\n",
    "sampled_data = unique_combinations.sample(n=50, random_state=1)\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(sampled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리기 (fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터가 저장되었습니다: ./refer/output/survey_pre_v1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "preprocessed_output_path = f'{file_path}survey_pre_v1.csv'\n",
    "\n",
    "\n",
    "def survey_processing(file_path, output_path):\n",
    "    # CSV 파일을 로드\n",
    "    survey_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 우선순위에 대한 가중치 매핑을 정의\n",
    "    priority_weights = {\n",
    "        \"건강\": \"health\",\n",
    "        \"여가시간\": \"free_time\",\n",
    "        \"학업 및 자기계발\": \"edu\",\n",
    "        \"업무\": \"work\",\n",
    "        \"집안일\": \"chores\",\n",
    "        None: \"category_else\"\n",
    "    }\n",
    "    \n",
    "    # 각 우선순위 컬럼에 대해 가중치를 적용\n",
    "    for i in range(1, 6):\n",
    "        column_name = f\"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [{i} 순위]\"\n",
    "        survey_df[column_name] = survey_df[column_name].map(priority_weights)\n",
    "    \n",
    "    # 필요한 컬럼들만 선택하고 리네임\n",
    "    columns_to_keep = [\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\"\n",
    "    ]\n",
    "    \n",
    "    survey_df = survey_df[columns_to_keep]\n",
    "    \n",
    "    # 컬럼명을 변환\n",
    "    column_mapping = {\n",
    "        \"설문자의 나이(만)는 어떻게 되십니까?\": \"age\",\n",
    "        \"설문자의 해당사항을 체크해주세요.\": \"job\",\n",
    "        \"설문자의 MBTI는 무엇입니까?\": \"mbti\",\n",
    "        \"설문자의 성별은 어떻게 되십니까?\": \"gender\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\": \"priority_1\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\": \"priority_2\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\": \"priority_3\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\": \"priority_4\",\n",
    "        \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\": \"priority_5\"\n",
    "    }\n",
    "    \n",
    "    survey_df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "    # 새로운 컬럼 'category_else'를 추가하고 모든 값을 0으로 설정\n",
    "    survey_df[\"category_else\"] = 0\n",
    "    \n",
    "    # 나이, 직업, MBTI 컬럼을 숫자 코드로 변환\n",
    "    age_mapping = {\n",
    "        \"0~14세\": (0, 14),\n",
    "        \"15~19세\": (15, 19),\n",
    "        \"20~24세\": (20, 24),\n",
    "        \"25~30세\": (25, 30),\n",
    "        \"31세 이상\": (31, 45)\n",
    "    }\n",
    "    job_mapping = {\n",
    "        \"초/중학생\": \"000\",\n",
    "        \"고등학생\": \"001\",\n",
    "        \"대학생 / 저학년 (1-2학년)\": \"002\",\n",
    "        \"대학생 / 고학년(3-4학년)\": \"003\",\n",
    "        \"구직자\": \"004\",\n",
    "        \"직장인\": \"005\",\n",
    "        \"자영업자\": \"006\",\n",
    "        \"프리랜서\": \"007\",\n",
    "        \"주부\": \"008\",\n",
    "        \"기타\": \"009\"\n",
    "    }\n",
    "    mbti_mapping = {\n",
    "        \"INTJ\": \"00\",\n",
    "        \"INTP\": \"01\",\n",
    "        \"ENTJ\": \"02\",\n",
    "        \"ENTP\": \"03\",\n",
    "        \"INFJ\": \"04\",\n",
    "        \"INFP\": \"05\",\n",
    "        \"ENFJ\": \"06\",\n",
    "        \"ENFP\": \"07\",\n",
    "        \"ISTJ\": \"08\",\n",
    "        \"ISFJ\": \"09\",\n",
    "        \"ESTJ\": \"10\",\n",
    "        \"ESFJ\": \"11\",\n",
    "        \"ISTP\": \"12\",\n",
    "        \"ISFP\": \"13\",\n",
    "        \"ESTP\": \"14\",\n",
    "        \"ESFP\": \"15\"\n",
    "    }\n",
    "    gender_mapping = {\n",
    "        \"남\": 0,\n",
    "        \"여\": 1\n",
    "    }\n",
    "\n",
    "    # 나이, 직업, MBTI, 성별 컬럼을 숫자 코드로 변환\n",
    "    survey_df['age'] = survey_df['age'].map(lambda x: np.random.randint(age_mapping[x][0], age_mapping[x][1] + 1))\n",
    "    survey_df['job'] = survey_df['job'].map(job_mapping)\n",
    "    survey_df['mbti'] = survey_df['mbti'].str.upper().map(mbti_mapping)\n",
    "    survey_df['gender'] = survey_df['gender'].map(gender_mapping)\n",
    "\n",
    "    # 우선순위별로 각 항목에 가중치를 적용한 값을 할당\n",
    "    work_col = []\n",
    "    edu_col = []\n",
    "    free_time_col = []\n",
    "    health_col = []\n",
    "    chores_col = []\n",
    "\n",
    "    for _, row in survey_df.iterrows():\n",
    "        work = 0\n",
    "        edu = 0\n",
    "        free_time = 0\n",
    "        health = 0\n",
    "        chores = 0\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            if row[f'priority_{i}'] == 'work':\n",
    "                work = i\n",
    "            elif row[f'priority_{i}'] == 'edu':\n",
    "                edu = i\n",
    "            elif row[f'priority_{i}'] == 'free_time':\n",
    "                free_time = i\n",
    "            elif row[f'priority_{i}'] == 'health':\n",
    "                health = i\n",
    "            elif row[f'priority_{i}'] == 'chores':\n",
    "                chores = i\n",
    "        \n",
    "        work_col.append(work)\n",
    "        edu_col.append(edu)\n",
    "        free_time_col.append(free_time)\n",
    "        health_col.append(health)\n",
    "        chores_col.append(chores)\n",
    "    \n",
    "    survey_df['work'] = work_col\n",
    "    survey_df['edu'] = edu_col\n",
    "    survey_df['free_time'] = free_time_col\n",
    "    survey_df['health'] = health_col\n",
    "    survey_df['chores'] = chores_col\n",
    "    \n",
    "    # 사용하지 않는 우선순위 컬럼 삭제\n",
    "    survey_df.drop(columns=['priority_1', 'priority_2', 'priority_3', 'priority_4', 'priority_5'], inplace=True)\n",
    "    \n",
    "    # 컬럼 순서 재정렬\n",
    "    survey_df = survey_df[['age', 'job', 'mbti', 'gender', 'work', 'edu', 'free_time', 'health', 'chores', 'category_else']]\n",
    "    \n",
    "    # 수정된 데이터프레임을 새로운 CSV 파일로 저장\n",
    "    survey_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 오버샘플링된 데이터를 전처리\n",
    "survey_processing(f'{file_path}survey.csv', preprocessed_output_path)\n",
    "print(f\"전처리된 데이터가 저장되었습니다: {preprocessed_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = './refer/output/'\n",
    "data_path = f'{file_path}survey.csv'\n",
    "output_path = f'{file_path}survey_oversampled_v2.csv'\n",
    "preprocessed_output_path = f'{file_path}survey_preprocessed_v2.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "columns_to_keep = [\n",
    "    \"설문자의 나이(만)는 어떻게 되십니까?\",\n",
    "    \"설문자의 해당사항을 체크해주세요.\", # 직업\n",
    "    \"설문자의 MBTI는 무엇입니까?\",\n",
    "    \"설문자의 성별은 어떻게 되십니까?\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [1 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [2 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [3 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [4 순위]\",\n",
    "    \"본인이 생각하는 일과 별 중요도를 우선순위를 정하여 체크해주세요. (각 순위 별로 하나씩만 체크해주세요) [5 순위]\"\n",
    "]\n",
    "survey_df = survey_df[columns_to_keep]\n",
    "\n",
    "# 오버샘플링을 수행하는 함수\n",
    "def oversample_data(df, target_size=700000):\n",
    "    current_size = len(df)\n",
    "    if (target_size - current_size) > current_size:\n",
    "        oversample_count = target_size - current_size\n",
    "        oversampled_df = resample(df, replace=True, n_samples=oversample_count, random_state=42)\n",
    "        return pd.concat([df, oversampled_df], axis=0)\n",
    "    else:\n",
    "        return resample(df, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# 데이터를 70만 개로 오버샘플링\n",
    "oversampled_survey_df = oversample_data(survey_df, target_size=600000)\n",
    "\n",
    "# 더미 변수 생성\n",
    "categorical_features = columns_to_keep\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 전처리 파이프라인\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# 데이터 변환\n",
    "X = pipeline.fit_transform(oversampled_survey_df)\n",
    "\n",
    "# KMeans 클러스터링\n",
    "# 5순위 특성값에 맞게 클러스터 5로 설정\n",
    "# 5개로 쪼개진 클러스터에 각각 smote 적용하여 데이터 다양성 높이면서 클러스터 특성 유지\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(X, clusters)\n",
    "\n",
    "# 더미 변수를 원래 값으로 변환\n",
    "inverse_transformer = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "oversampled_df = pd.DataFrame(inverse_transformer.inverse_transform(X_resampled), columns=columns_to_keep)\n",
    "\n",
    "# 원래 survey_df의 인덱스를 저장\n",
    "original_index = survey_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampled_df에서 원래 oversampled_survey_df와 동일한 행을 제거\n",
    "\n",
    "\n",
    "# 최종 결과 저장\n",
    "unique_oversampled_df.to_csv(output_path, index=False)\n",
    "print(f\"오버샘플링 데이터 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting number of rows: 85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = './refer/output/'\n",
    "data_path = f'{file_path}survey_pre_v1.csv'\n",
    "output_path = f'{file_path}survey_fin_v1.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 오버샘플링을 수행하는 함수\n",
    "def oversample_data(df, target_size=700000):\n",
    "    current_size = len(df)\n",
    "    if (target_size - current_size) > current_size:\n",
    "        oversample_count = target_size - current_size\n",
    "        oversampled_df = resample(df, replace=True, n_samples=oversample_count, random_state=42)\n",
    "        return pd.concat([df, oversampled_df], axis=0)\n",
    "    else:\n",
    "        return resample(df, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# 데이터를 70만 개로 오버샘플링\n",
    "oversampled_survey_df = oversample_data(survey_df, target_size=60)\n",
    "\n",
    "# 수치형 데이터 표준화\n",
    "numeric_features = [\"work\", \"edu\", \"free_time\", \"health\", \"chores\", \"category_else\"]\n",
    "\n",
    "preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# 데이터 변환\n",
    "X = preprocessor.fit_transform(oversampled_survey_df[numeric_features])\n",
    "\n",
    "# KMeans 클러스터링\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(X, clusters)\n",
    "\n",
    "# Resampled 데이터를 원래 데이터프레임 형식으로 변환\n",
    "oversampled_df = pd.DataFrame(X_resampled, columns=numeric_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "      <th>category_else</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.083228</td>\n",
       "      <td>-1.651811</td>\n",
       "      <td>-0.808450</td>\n",
       "      <td>0.568796</td>\n",
       "      <td>0.720823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.314485</td>\n",
       "      <td>-0.115243</td>\n",
       "      <td>1.744549</td>\n",
       "      <td>-0.982467</td>\n",
       "      <td>0.159143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384371</td>\n",
       "      <td>-0.883527</td>\n",
       "      <td>-1.659449</td>\n",
       "      <td>1.344428</td>\n",
       "      <td>0.720823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.782084</td>\n",
       "      <td>-0.115243</td>\n",
       "      <td>-0.808450</td>\n",
       "      <td>-0.982467</td>\n",
       "      <td>-2.087579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.013342</td>\n",
       "      <td>0.653042</td>\n",
       "      <td>1.744549</td>\n",
       "      <td>0.568796</td>\n",
       "      <td>-0.964218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.013342</td>\n",
       "      <td>0.653042</td>\n",
       "      <td>1.744549</td>\n",
       "      <td>0.568796</td>\n",
       "      <td>-0.964218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.819059</td>\n",
       "      <td>1.207742</td>\n",
       "      <td>1.130129</td>\n",
       "      <td>0.137543</td>\n",
       "      <td>-1.276514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-1.013342</td>\n",
       "      <td>-0.741900</td>\n",
       "      <td>0.841258</td>\n",
       "      <td>2.072399</td>\n",
       "      <td>-2.018552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-1.013342</td>\n",
       "      <td>0.651845</td>\n",
       "      <td>1.744549</td>\n",
       "      <td>0.568796</td>\n",
       "      <td>-0.963343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.013342</td>\n",
       "      <td>0.659025</td>\n",
       "      <td>1.737921</td>\n",
       "      <td>0.568796</td>\n",
       "      <td>-0.964218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        work       edu  free_time    health    chores  category_else  age  \\\n",
       "0   1.083228 -1.651811  -0.808450  0.568796  0.720823            0.0   37   \n",
       "1  -0.314485 -0.115243   1.744549 -0.982467  0.159143            0.0   23   \n",
       "2   0.384371 -0.883527  -1.659449  1.344428  0.720823            0.0   23   \n",
       "3   1.782084 -0.115243  -0.808450 -0.982467 -2.087579            0.0   25   \n",
       "4  -1.013342  0.653042   1.744549  0.568796 -0.964218            0.0   40   \n",
       "..       ...       ...        ...       ...       ...            ...  ...   \n",
       "80 -1.013342  0.653042   1.744549  0.568796 -0.964218            0.0   41   \n",
       "81 -0.819059  1.207742   1.130129  0.137543 -1.276514            0.0   30   \n",
       "82 -1.013342 -0.741900   0.841258  2.072399 -2.018552            0.0   40   \n",
       "83 -1.013342  0.651845   1.744549  0.568796 -0.963343            0.0   25   \n",
       "84 -1.013342  0.659025   1.737921  0.568796 -0.964218            0.0   24   \n",
       "\n",
       "    job  mbti  gender  \n",
       "0     8    11       1  \n",
       "1     3     1       0  \n",
       "2     3     3       1  \n",
       "3     5     7       1  \n",
       "4     8    11       1  \n",
       "..  ...   ...     ...  \n",
       "80    8     5       1  \n",
       "81    4    12       0  \n",
       "82    8    11       1  \n",
       "83    4     1       0  \n",
       "84    3     4       1  \n",
       "\n",
       "[85 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 나머지 컬럼들도 오버샘플링된 길이에 맞춰 할당\n",
    "other_columns = [col for col in oversampled_survey_df.columns if col not in numeric_features]\n",
    "for col in other_columns:\n",
    "    # SMOTE로 생성된 샘플 수만큼 임의로 데이터 할당\n",
    "    repeated_values = pd.Series(oversampled_survey_df[col].values).sample(n=len(X_resampled), replace=True, random_state=42).values\n",
    "    oversampled_df[col] = repeated_values\n",
    "\n",
    "# 결과 저장\n",
    "oversampled_df.to_csv(output_path, index=False)\n",
    "print(f\"Resulting number of rows: {oversampled_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df.iloc[:, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.equals(survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[cols] == survey_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'A' : [1, 2, 3], \n",
    "    'B' : [4, 5, 6],\n",
    "    'C' : [7, 8, 9] \n",
    "}\n",
    "df1 = pd.DataFrame(data)\n",
    "df2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C\n",
       "0  True  True  True\n",
       "1  True  True  True\n",
       "2  True  True  True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 == df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = test_df.isin(survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    45\n",
       "True     40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.any(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work             False\n",
       "edu              False\n",
       "free_time        False\n",
       "health           False\n",
       "chores           False\n",
       "category_else    False\n",
       "age               True\n",
       "job               True\n",
       "mbti              True\n",
       "gender            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting number of rows: 71715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = './refer/output/'\n",
    "data_path = f'{file_path}survey_pre_v1.csv'\n",
    "output_path = f'{file_path}smote_v1.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 오버샘플링을 수행하는 함수\n",
    "def oversample_data(df, target_size=700000):\n",
    "    current_size = len(df)\n",
    "    if (target_size - current_size) > current_size:\n",
    "        oversample_count = target_size - current_size\n",
    "        oversampled_df = resample(df, replace=True, n_samples=oversample_count, random_state=42)\n",
    "        return pd.concat([df, oversampled_df], axis=0)\n",
    "    else:\n",
    "        return resample(df, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# 데이터를 6만 개로 오버샘플링\n",
    "oversampled_survey_df = oversample_data(survey_df, target_size=50000)\n",
    "\n",
    "# 수치형 데이터 선택\n",
    "numeric_features = [\"work\", \"edu\", \"free_time\", \"health\", \"chores\"]\n",
    "\n",
    "# KMeans 클러스터링\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(oversampled_survey_df[numeric_features])\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(oversampled_survey_df[numeric_features], clusters)\n",
    "\n",
    "# SMOTE로 생성된 데이터에 1씩 더하기\n",
    "X_resampled += 1\n",
    "\n",
    "# Resampled 데이터를 원래 데이터프레임 형식으로 변환\n",
    "oversampled_df = pd.DataFrame(X_resampled, columns=numeric_features)\n",
    "\n",
    "# 나머지 컬럼들도 오버샘플링된 길이에 맞춰 할당\n",
    "other_columns = [col for col in oversampled_survey_df.columns if col not in numeric_features]\n",
    "for col in other_columns:\n",
    "    # SMOTE로 생성된 샘플 수만큼 임의로 데이터 할당\n",
    "    repeated_values = pd.Series(oversampled_survey_df[col].values).sample(n=len(X_resampled), replace=True, random_state=42).values\n",
    "    oversampled_df[col] = repeated_values\n",
    "\n",
    "# 결과 저장\n",
    "oversampled_df.to_csv(output_path, index=False)\n",
    "print(f\"Resulting number of rows: {oversampled_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting number of rows: 45030\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = './refer/output/'\n",
    "data_path = f'{file_path}survey_pre_v1.csv'\n",
    "output_path = f'{file_path}smote_v2.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 오버샘플링을 수행하는 함수\n",
    "def oversample_data(df, target_size=30000):\n",
    "    current_size = len(df)\n",
    "    if (target_size - current_size) > current_size:\n",
    "        oversample_count = target_size - current_size\n",
    "        oversampled_df = resample(df, replace=True, n_samples=oversample_count, random_state=42)\n",
    "        return pd.concat([df, oversampled_df], axis=0)\n",
    "    else:\n",
    "        return resample(df, replace=True, n_samples=target_size, random_state=42)\n",
    "\n",
    "# 데이터를 3만 개로 오버샘플링\n",
    "oversampled_survey_df = oversample_data(survey_df, target_size=30000)\n",
    "\n",
    "# 수치형 데이터 선택\n",
    "numeric_features = [\"work\", \"edu\", \"free_time\", \"health\", \"chores\"]\n",
    "\n",
    "# KMeans 클러스터링\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(oversampled_survey_df[numeric_features])\n",
    "\n",
    "# 각 클래스의 샘플 수를 기준으로 sampling_strategy 생성\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "# 최빈 클래스의 샘플 수를 기준으로 소수 클래스 비율 차등 조정\n",
    "max_count = max(class_counts.values())\n",
    "sampling_strategy = {}\n",
    "for cls, count in class_counts.items():\n",
    "    if count < max_count:\n",
    "        # 클래스의 샘플 수가 적을수록 더 많은 샘플을 생성\n",
    "        ratio = max_count / count\n",
    "        sampling_strategy[cls] = int(count * ratio)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, clusters_resampled = smote.fit_resample(oversampled_survey_df[numeric_features], clusters)\n",
    "\n",
    "# SMOTE로 생성된 데이터에 1씩 더하기\n",
    "X_resampled += 1\n",
    "\n",
    "# Resampled 데이터를 원래 데이터프레임 형식으로 변환\n",
    "oversampled_df = pd.DataFrame(X_resampled, columns=numeric_features)\n",
    "\n",
    "# 나머지 컬럼들도 오버샘플링된 길이에 맞춰 할당\n",
    "other_columns = [col for col in oversampled_survey_df.columns if col not in numeric_features]\n",
    "for col in other_columns:\n",
    "    # SMOTE로 생성된 샘플 수만큼 임의로 데이터 할당\n",
    "    repeated_values = pd.Series(oversampled_survey_df[col].values).sample(n=len(X_resampled), replace=True, random_state=42).values\n",
    "    oversampled_df[col] = repeated_values\n",
    "\n",
    "# 결과 저장\n",
    "oversampled_df.to_csv(output_path, index=False)\n",
    "print(f\"Resulting number of rows: {oversampled_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>edu</th>\n",
       "      <th>free_time</th>\n",
       "      <th>health</th>\n",
       "      <th>chores</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>mbti</th>\n",
       "      <th>gender</th>\n",
       "      <th>category_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45025</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45026</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45027</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45028</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45029</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45030 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       work  edu  free_time  health  chores  age  job  mbti  gender  \\\n",
       "0         7    6          5       4       8   22    3     1       1   \n",
       "1         8    6          5       4       7   30    4     3       0   \n",
       "2         4    5          6       7       8   26    3    15       1   \n",
       "3         4    6          5       7       8   40    5     6       1   \n",
       "4         7    6          8       4       5   20    2    14       1   \n",
       "...     ...  ...        ...     ...     ...  ...  ...   ...     ...   \n",
       "45025     5    7          4       6       8   30    3     9       0   \n",
       "45026     4    5          6       7       8   32    5     5       1   \n",
       "45027     4    6          5       7       8   25    5    12       1   \n",
       "45028     5    7          4       6       8   26    4    15       1   \n",
       "45029     4    6          5       7       8   30    4     3       0   \n",
       "\n",
       "       category_else  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "45025              0  \n",
       "45026              0  \n",
       "45027              0  \n",
       "45028              0  \n",
       "45029              0  \n",
       "\n",
       "[45030 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work\n",
       "3    18\n",
       "4    14\n",
       "5     9\n",
       "6     7\n",
       "7     6\n",
       "0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df['work'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work\n",
       "3    31249\n",
       "4    22431\n",
       "5    19624\n",
       "7    17554\n",
       "6    13925\n",
       "0     1982\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df['work'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oversampled_df['work'] == oversampled_df['edu']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oversampled_df['work'] == oversampled_df['free_time']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oversampled_df['work'] == oversampled_df['health']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oversampled_df['work'] == oversampled_df['chores']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oversampled_df['work'] == oversampled_df['category_else']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.read_csv(f'{file_path}smote_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = pd.read_csv(f'{file_path}smote_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.concat((v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.to_csv(f'{file_path}user_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting number of rows: 116745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "data_path = f'{file_path}user_data.csv'\n",
    "output_path = f'{file_path}user_data_ranked_v1.csv'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "survey_df = pd.read_csv(data_path)\n",
    "\n",
    "# 수치형 데이터 선택\n",
    "numeric_features = [\"work\", \"edu\", \"free_time\", \"health\", \"chores\", \"category_else\"]\n",
    "\n",
    "# 각 행의 값을 순위로 변환하여 1부터 6까지 나타내기\n",
    "for index, row in survey_df.iterrows():\n",
    "    rank = row[numeric_features].rank(method='first', ascending=False).astype(int)\n",
    "    survey_df.loc[index, numeric_features] = rank.values\n",
    "\n",
    "# 결과 저장\n",
    "survey_df.to_csv(output_path, index=False)\n",
    "print(f\"Resulting number of rows: {survey_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
