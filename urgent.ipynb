{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "from ray.air import session\n",
    "import os\n",
    "import multiprocessing\n",
    "from refer.module.func import debug_message, save_model_with_versioning, trial_dirname_creator\n",
    "\n",
    "# 시스템 정보 가져오기\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Ray 초기화\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# 데이터 로드 및 전처리 (DB에서 데이터 가져오기로 수정필요)\n",
    "file_path = './refer/output/'\n",
    "debug_message(\"작업 긴급도 데이터 로드 중...\")\n",
    "data = pd.read_csv(f'{file_path}data.csv')\n",
    "debug_message(\"작업 긴급도 데이터 로드 완료\")\n",
    "\n",
    "# 초기 긴급도 기준 생성 (여기 컬럼명 변경 필요)\n",
    "debug_message(\"긴급도 관련 데이터 생성 중...\")\n",
    "data['start_date'] = pd.to_datetime(data['start_date'])\n",
    "data['end_date'] = pd.to_datetime(data['end_date'])\n",
    "data['days_left'] = (data['end_date'] - data['start_date']).dt.days\n",
    "data['urgency'] = 1 / (data['days_left'] + 1)  # 마감일이 가까울수록 긴급도가 높아짐\n",
    "debug_message(\"긴급도 관련 데이터 생성 완료\")\n",
    "\n",
    "# 긴급도 모델을 위한 입력 데이터 준비 (컬럼명 변경 필요)\n",
    "X_urgency = data[['start_date', 'end_date', 'complexity']].copy()\n",
    "X_urgency['start_date'] = (X_urgency['start_date'] - X_urgency['start_date'].min()).dt.days\n",
    "X_urgency['end_date'] = (X_urgency['end_date'] - X_urgency['end_date'].min()).dt.days\n",
    "y_urgency = data['urgency'].values\n",
    "\n",
    "# 데이터 정규화\n",
    "debug_message(\"데이터 정규화 중...\")\n",
    "scaler = StandardScaler()  # RobustScaler를 사용할 수도 있음\n",
    "X_urgency = scaler.fit_transform(X_urgency)\n",
    "debug_message(\"데이터 정규화 완료\")\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "debug_message(\"데이터 학습용 및 테스트용 분할 중...\")\n",
    "X_train_urgency, X_test_urgency, y_train_urgency, y_test_urgency = train_test_split(X_urgency, y_urgency, test_size=0.2, random_state=42)\n",
    "debug_message(\"데이터 학습용 및 테스트용 분할 완료\")\n",
    "print(len(X_train_urgency))\n",
    "print(len(X_test_urgency))\n",
    "print(len(y_train_urgency))\n",
    "print(len(y_test_urgency))\n",
    "\n",
    "# 모델 생성 함수\n",
    "def create_urgency_model(config):\n",
    "    debug_message(\"모델 생성 중...\")\n",
    "    model = Sequential()\n",
    "    model.add(Dense(config[\"hidden_layer1_size\"], input_dim=X_train_urgency.shape[1], activation='relu', \n",
    "                    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=config[\"l1_lambda\"], l2=config[\"l2_lambda\"])))\n",
    "    if config[\"batch_norm\"]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(config[\"dropout_rate\"]))\n",
    "    model.add(Dense(config[\"hidden_layer2_size\"], activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=config[\"l1_lambda\"], l2=config[\"l2_lambda\"])))\n",
    "    if config[\"batch_norm\"]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(config[\"dropout_rate\"]))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer_name = config[\"optimizer\"]\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"lr\"])\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"lr\"])\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=config[\"lr\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])  # MSE를 메트릭으로 추가\n",
    "    debug_message(\"모델 생성 완료\")\n",
    "    return model\n",
    "\n",
    "# 학습 함수\n",
    "def train_urgency_model(config, X_train_urgency, y_train_urgency, X_test_urgency, y_test_urgency):\n",
    "    print(\"train_urgency_model 함수에서 config는 \", config)\n",
    "    try:\n",
    "        debug_message(\"모델 학습 시작...\")\n",
    "        model = create_urgency_model(config)\n",
    "        log_dir = os.path.join(\"logs\", f\"trial_{tune.get_trial_id()[:8]}\")\n",
    "        os.makedirs(log_dir, exist_ok=True)  # 로그 디렉토리가 없으면 생성\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        tune_report_callback = TuneReportCallback({\"mean_squared_error\": \"val_mse\"})\n",
    "        history = model.fit(X_train_urgency, y_train_urgency, \n",
    "                            epochs=config[\"epochs\"], \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            validation_split=0.2, \n",
    "                            verbose=1,\n",
    "                            callbacks=[tensorboard_callback, tune_report_callback])\n",
    "        debug_message(\"모델 학습 완료\")\n",
    "        \n",
    "        # 모델 평가\n",
    "        debug_message(\"모델 평가 중...\")\n",
    "        train_loss = model.evaluate(X_train_urgency, y_train_urgency, verbose=1)\n",
    "        val_loss = model.evaluate(X_test_urgency, y_test_urgency, verbose=1)\n",
    "        y_pred_train = model.predict(X_train_urgency)\n",
    "        y_pred_test = model.predict(X_test_urgency)\n",
    "        train_mse = mean_squared_error(y_train_urgency, y_pred_train)\n",
    "        val_mse = mean_squared_error(y_test_urgency, y_pred_test)\n",
    "        debug_message(\"모델 평가 완료\")\n",
    "        \n",
    "        # 평가 결과 보고\n",
    "        session.report({\"mean_squared_error\": val_mse, \"train_loss\": train_loss, \"val_loss\": val_loss, \"train_mse\": train_mse, \"val_mse\": val_mse})\n",
    "    except Exception as e:\n",
    "        debug_message(f\"학습 중 오류 발생: {str(e)}\")\n",
    "        session.report({\"mean_squared_error\": float(\"inf\"), \"train_loss\": float(\"inf\"), \"val_loss\": float(\"inf\"), \"train_mse\": float(\"inf\"), \"val_mse\": float(\"inf\")})\n",
    "\n",
    "# Ray Tune을 사용한 하이퍼파라미터 최적화\n",
    "def tune_urgency_model():\n",
    "    config = {\n",
    "        'lr': tune.choice([0.0001, 0.01]),  # 학습률 결정: 학습 과정에서 가중치가 조정되는 속도\n",
    "        'batch_size': tune.choice([16, 64]),  # 배치 크기: 한 번의 훈련 반복에서 사용되는 샘플의 수\n",
    "        'epochs': tune.choice([10, 20]),  # 에포크 수: 전체 데이터셋을 훈련하는 반복 횟수\n",
    "        'hidden_layer1_size': tune.choice([64, 256]),  # 첫 번째 은닉층의 노드 수 결정: 모델의 복잡성 조절\n",
    "        'hidden_layer2_size': tune.choice([32, 128]),  # 두 번째 은닉층의 노드 수 결정: 모델의 복잡성 조절\n",
    "        'dropout_rate': tune.choice([0.1, 0.3]),  # 드롭아웃 비율: 과적합을 방지하기 위해 일부 뉴런을 무작위로 제외\n",
    "        'batch_norm': tune.choice([True, False]),  # 배치 정규화 사용 여부: 학습을 안정화하고 가속화\n",
    "        'optimizer': tune.choice(['adam', 'sgd', 'rmsprop']),  # 옵티마이저: 학습 과정에서 가중치를 업데이트하는 방법 결정\n",
    "        'l2_lambda': tune.choice([0.0001, 0.01]),  # L2 정규화: 가중치의 크기를 제한하여 과적합 방지\n",
    "        'l1_lambda': tune.choice([0.0001, 0.01]),  # L1 정규화: 가중치의 크기를 제한하여 과적합 방지\n",
    "        'num_cpus': 4,  # CPU 수 설정\n",
    "        'num_gpus': 0   # GPU 수 설정\n",
    "    }\n",
    "    # config에서 최대 에포크 값 추출\n",
    "    max_epochs = max(config['epochs'].categories)\n",
    "\n",
    "    # ASHA 스케줄러 설정: Asynchronous Successive Halving Algorithm\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_epochs,  # 각 실험에서 실행할 최대 시간 또는 최대 스텝 (여기서는 에포크 수)\n",
    "        grace_period=1,  # 각 실험을 종료하기 전에 최소한으로 실행할 시간 또는 스텝\n",
    "        reduction_factor=2  # 리소스를 절감하기 위해 각 실험을 종료할 때마다 감소시킬 비율\n",
    "    )\n",
    "    \n",
    "    # Ray Tune을 사용하여 하이퍼파라미터 최적화 수행\n",
    "    debug_message(\"Ray Tune 하이퍼파라미터 최적화 시작...\")\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(train_urgency_model, X_train_urgency=X_train_urgency, y_train_urgency=y_train_urgency, X_test_urgency=X_test_urgency, y_test_urgency=y_test_urgency),  # 학습 함수\n",
    "        resources_per_trial={\"cpu\": config['num_cpus'], \"gpu\": config['num_gpus']},  # 각 시도에서 사용할 리소스 설정\n",
    "        config=config,  # 하이퍼파라미터 설정\n",
    "        num_samples=1,  # 샘플링 횟수: 각 설정으로 몇 번의 실험을 실행할지\n",
    "        scheduler=scheduler,  # 스케줄러 설정\n",
    "        verbose=1,  # 학습 과정 출력 레벨: 0은 출력 없음, 1은 진행 상태 막대 표시, 2는 자세한 로그 출력\n",
    "        trial_dirname_creator=trial_dirname_creator,  # 디렉토리 이름 생성 함수\n",
    "        metric='mean_squared_error',\n",
    "        mode='min'\n",
    "    )\n",
    "    debug_message(\"Ray Tune 하이퍼파라미터 최적화 완료\")\n",
    "    \n",
    "    # 최적의 하이퍼파라미터 출력\n",
    "    print(\"Best config: \", analysis.get_best_config(metric=\"mean_squared_error\", mode=\"min\"))\n",
    "    return analysis.get_best_config(metric=\"mean_squared_error\", mode=\"min\"), analysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 최적의 하이퍼파라미터 찾기\n",
    "    debug_message(\"최적의 하이퍼파라미터 찾기 시작...\")\n",
    "    best_config, analysis = tune_urgency_model()\n",
    "    debug_message(\"최적의 하이퍼파라미터 찾기 완료\")\n",
    "    \n",
    "    debug_message(\"최적의 하이퍼파라미터로 모델 재학습 중...\")\n",
    "    best_model = create_urgency_model(best_config)\n",
    "    best_model.fit(X_train_urgency, y_train_urgency, epochs=best_config['epochs'], batch_size=best_config['batch_size'], validation_split=0.2, verbose=1)\n",
    "    debug_message(\"모델 재학습 완료\")\n",
    "    \n",
    "    # 최종 평가 결과\n",
    "    debug_message(\"최종 평가 결과 분석 중...\")\n",
    "    best_trial = analysis.get_best_trial(\"mean_squared_error\", mode=\"min\", scope=\"all\")\n",
    "    best_trained_model = create_urgency_model(best_trial.config)\n",
    "    best_checkpoint_dir = analysis.get_best_checkpoint(best_trial)\n",
    "\n",
    "    if best_checkpoint_dir:\n",
    "        model_path = os.path.join(best_checkpoint_dir, \"checkpoint\")\n",
    "        best_trained_model.load_weights(model_path)\n",
    "\n",
    "    debug_message(\"최종 모델 평가 중...\")\n",
    "    train_loss = best_trained_model.evaluate(X_train_urgency, y_train_urgency, verbose=1)\n",
    "    test_loss = best_trained_model.evaluate(X_test_urgency, y_test_urgency, verbose=1)\n",
    "\n",
    "    y_pred_train = best_trained_model.predict(X_train_urgency)\n",
    "    y_pred_test = best_trained_model.predict(X_test_urgency)\n",
    "    train_mse = mean_squared_error(y_train_urgency, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_test_urgency, y_pred_test)\n",
    "    \n",
    "    log_dir = os.path.join(\"logs\", \"final_model\")\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 로그 디렉토리가 없으면 생성\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    print(f'훈련 MSE: {train_mse:.4f}')\n",
    "    print(f'테스트 MSE: {test_mse:.4f}')\n",
    "    debug_message(\"최종 모델 평가 완료\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    debug_message(\"모델 저장 중...\")\n",
    "    saved_filename = save_model_with_versioning(best_trained_model, file_path, \"urgency_model\")\n",
    "    debug_message(f\"모델 저장 완료: {saved_filename}\")\n",
    "    \n",
    "    print(f\"Initial urgency model created and saved as {saved_filename}.\")\n",
    "\n",
    "    # Ray 종료\n",
    "    ray.shutdown()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
